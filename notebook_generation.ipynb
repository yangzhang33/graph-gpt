{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "# import fires\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.cuda.amp import GradScaler\n",
    "# import deepspeed\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from pprint import pprint, pformat\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from timm.utils import ModelEmaV3\n",
    "from timm.models import load_checkpoint\n",
    "from timm.utils.model import unwrap_model, get_state_dict\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ModuleNotFoundError:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import (\n",
    "    collator,\n",
    "    vocab_builder,\n",
    "    tokenizer,\n",
    "    read_dataset,\n",
    "    OdpsTableIterableDataset,\n",
    ")\n",
    "from src.models import (\n",
    "    GraphGPTConfig,\n",
    "    GraphGPTCausal,\n",
    "    GraphGPT2Config,\n",
    "    GraphGPT2Causal,\n",
    "    GraphBertConfig,\n",
    "    GraphBertForMaskedLM,\n",
    ")\n",
    "from src.utils import (\n",
    "    conf_utils,\n",
    "    loss_utils,\n",
    "    loader_utils,\n",
    "    tokenizer_utils,\n",
    "    modules_utils,\n",
    "    misc_utils,\n",
    "    print_trainable_parameters,\n",
    "    print_params,\n",
    "    inspect_tokenization_results,\n",
    "    set_up_shuffle_and_sampler,\n",
    "    worker_init_fn_seed,\n",
    ")\n",
    "\n",
    "dict_models = {\n",
    "    \"graphgpt2\": (GraphGPT2Causal, GraphGPT2Config),\n",
    "    \"graphgpt\": (GraphGPTCausal, GraphGPTConfig),\n",
    "    \"graphbert\": (GraphBertForMaskedLM, GraphBertConfig),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir: str = \"../data/OGB\"\n",
    "tables: str = \"\"\n",
    "# deepspeed_config = \"./examples/ds_config2_pt.json\"\n",
    "intermediate_size = 0\n",
    "num_attention_heads = 0\n",
    "hidden_size = 512\n",
    "num_hidden_layers = 8\n",
    "task_type='pretrain'\n",
    "causal_attention = 1\n",
    "lr=3e-4\n",
    "model_type = 'graphgpt'\n",
    "output_dir='./exp/models/pcqm4m-v2/test'\n",
    "pretrain_cpt = '/datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1'\n",
    "samples_per_saving=1000000\n",
    "\n",
    "batch_size = 1024\n",
    "stack_method = 'short'\n",
    "\n",
    "pack_tokens = 0\n",
    "max_position_embeddings = 1024\n",
    "\n",
    "task_type='pretrain'\n",
    "total_tokens=1e9\n",
    "batch_size = 1024\n",
    "warmup_tokens=1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 512 intermediate_size: 2048 num_attention_heads: 8 num_hidden_layers: 8 causal_attention: 1\n",
      "gpu_name: NVIDIA RTX A6000 GraphModel: <class 'src.models.graphgpt.modeling_graphgpt.GraphGPTCausal'> GraphModelConfig: <class 'src.models.graphgpt.configuration_graphgpt.GraphGPTConfig'>\n"
     ]
    }
   ],
   "source": [
    "use_tb_writer = False           # use tensorboard writer\n",
    "use_ema = False # False # use exponential moving average to smooth model\n",
    "use_deepspeed = False # True # use deepspeed for training, good to set scheduler\n",
    "if (intermediate_size == 0) and (num_attention_heads == 0): # True\n",
    "    (\n",
    "        hidden_size,\n",
    "        intermediate_size,\n",
    "        num_attention_heads,\n",
    "        num_hidden_layers,\n",
    "    ) = modules_utils.set_up_model_architect(\n",
    "        hidden_size=hidden_size, num_hidden_layers=num_hidden_layers # 768 24 related to model names intermediate_size = hidden_size * 4, num_attention_heads = hidden_size // 64\n",
    "    )# 768 3072 12 24\n",
    "causal_attention = 0 if task_type == \"pretrain-mlm\" else causal_attention\n",
    "print('hidden_size:', hidden_size, 'intermediate_size:', intermediate_size, 'num_attention_heads:', num_attention_heads, 'num_hidden_layers:', num_hidden_layers, 'causal_attention:', causal_attention) # 768 3072 12 24 1\n",
    "\n",
    "\n",
    "# #########################\n",
    "# betas = (0.9, 0.95) # used in AdamW optimizer, important for config beta\n",
    "# #########################\n",
    "# # lr * 0.1 -> from llama2 pre-train settings\n",
    "# min_lr = lr * 0.1 if use_deepspeed else 0    # used in scheduler, when not using deepspeed.\n",
    "# #########################\n",
    "gpu_name = torch.cuda.get_device_name()\n",
    "GraphModel, GraphModelConfig = dict_models[model_type] # Not instantiate yet\n",
    "print('gpu_name:', gpu_name, 'GraphModel:', GraphModel, 'GraphModelConfig:', GraphModelConfig) \n",
    "\n",
    "if os.path.exists(os.path.join(output_dir, \"log.csv\")):\n",
    "    print(\n",
    "        f\"log file {os.path.join(output_dir, 'log.csv')} exists, resume training from {output_dir} instead of initializing from pre-train ckp {pretrain_cpt}!\"\n",
    "    )\n",
    "    pretrain_cpt = output_dir\n",
    "\n",
    "\n",
    "# # 0. init distributed train and get gpu/device info\n",
    "# dist.init_process_group(backend=\"nccl\", init_method=\"env://\")  # for distributed training\n",
    "# dist.barrier() # for sync training\n",
    "# world_size = dist.get_world_size() # 1 # number of GPUs\n",
    "# rank = dist.get_rank() # 0 # current GPU index\n",
    "# local_rank = os.environ.get(\"LOCAL_RANK\") # 0 # current GPU index local to the node\n",
    "# print(f\"\\nworld size: {world_size}, rank: {rank}, local rank: {local_rank}\") # 1 0 0\n",
    "# rnd_seed = torch.random.initial_seed() - rank\n",
    "# random.seed(rnd_seed)\n",
    "# print(f\"seed random with {rnd_seed}\") # 1234\n",
    "# steps_per_saving = samples_per_saving // (world_size * batch_size) # 1000000 // (1 * 1024) = 976\n",
    "# print(f\"\\nsteps_per_saving: {steps_per_saving}\") # 976\n",
    "# params = print_params(**locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer config loading\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = \"./zhang_test/tokenizer_config.json\"\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    tokenizer_config = json.load(json_file)\n",
    "\n",
    "# Print the loaded data\n",
    "# pprint(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked_feat: 13, next_n_token: 13, embed_dim: 0\n"
     ]
    }
   ],
   "source": [
    "# 1.1 read configuration\n",
    "assert \"pretrain\" in tokenizer_config[\"task_type\"]\n",
    "assert (\n",
    "    tokenizer_config[\"semantics\"][\"attr_assignment\"]   # first\n",
    "    in tokenizer_utils.ATTR_ASSIGNMENT_TYPES   # ATTR_ASSIGNMENT_TYPES = {\"first\", \"last\", \"random\", \"all\", \"mix\"}\n",
    ")\n",
    "# pprint(tokenizer_config)\n",
    "if tokenizer_config[\"tokenizer_class\"] == \"StackedGSTTokenizer\":\n",
    "    attr_dim = (\n",
    "        tokenizer_config[\"semantics\"][\"edge\"][\"dim\"] # 3\n",
    "        + tokenizer_config[\"semantics\"][\"node\"][\"dim\"] # 9\n",
    "    ) # 12\n",
    "    assert stack_method in (\"short\", \"long\", None), f\"stack_method: {stack_method}\" # short\n",
    "    if tokenizer_config[\"structure\"][\"edge\"][\"remove_edge_type_token\"]: # True\n",
    "        stacked_feat = 1 + attr_dim\n",
    "    else:\n",
    "        stacked_feat = 2 + attr_dim\n",
    "    next_n_token = stacked_feat\n",
    "else:\n",
    "    stacked_feat = 1\n",
    "    next_n_token = 1 # maybe how many pack of tokens to predict\n",
    "embed_dim = tokenizer_config[\"semantics\"][\"node\"].get(\n",
    "    \"embed_dim\", 0\n",
    ") + tokenizer_config[\"semantics\"][\"edge\"].get(\"embed_dim\", 0) # 0\n",
    "print(\n",
    "    f\"stacked_feat: {stacked_feat}, next_n_token: {next_n_token}, embed_dim: {embed_dim}\" # 13 13 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-16 16:37:43.563652] Loading vocab from ./data/OGB/pcqm4m-v2/vocab512_stacked ...\n",
      "[2025-05-16 16:37:43.566104]\n",
      "{   '0': 22,\n",
      "    '1': 23,\n",
      "    '10': 32,\n",
      "    '100': 122,\n",
      "    '101': 123,\n",
      "    '102': 124,\n",
      "    '103': 125,\n",
      "    '104': 126,\n",
      "    '105': 127,\n",
      "    '106': 128,\n",
      "    '107': 129,\n",
      "    '108': 130,\n",
      "    '109': 131,\n",
      "    '11': 33,\n",
      "    '110': 132,\n",
      "    '111': 133,\n",
      "    '112': 134,\n",
      "    '113': 135,\n",
      "    '114': 136,\n",
      "    '115': 137,\n",
      "    '116': 138,\n",
      "    '117': 139,\n",
      "    '118': 140,\n",
      "    '119': 141,\n",
      "    '12': 34,\n",
      "    '120': 142,\n",
      "    '121': 143,\n",
      "    '122': 144,\n",
      "    '123': 145,\n",
      "    '124': 146,\n",
      "    '125': 147,\n",
      "    '126': 148,\n",
      "    '127': 149,\n",
      "    '128': 150,\n",
      "    '129': 151,\n",
      "    '13': 35,\n",
      "    '130': 152,\n",
      "    '131': 153,\n",
      "    '132': 154,\n",
      "    '133': 155,\n",
      "    '134': 156,\n",
      "    '135': 157,\n",
      "    '136': 158,\n",
      "    '137': 159,\n",
      "    '138': 160,\n",
      "    '139': 161,\n",
      "    '14': 36,\n",
      "    '140': 162,\n",
      "    '141': 163,\n",
      "    '142': 164,\n",
      "    '143': 165,\n",
      "    '144': 166,\n",
      "    '145': 167,\n",
      "    '146': 168,\n",
      "    '147': 169,\n",
      "    '148': 170,\n",
      "    '149': 171,\n",
      "    '15': 37,\n",
      "    '150': 172,\n",
      "    '151': 173,\n",
      "    '152': 174,\n",
      "    '153': 175,\n",
      "    '154': 176,\n",
      "    '155': 177,\n",
      "    '156': 178,\n",
      "    '157': 179,\n",
      "    '158': 180,\n",
      "    '159': 181,\n",
      "    '16': 38,\n",
      "    '160': 182,\n",
      "    '161': 183,\n",
      "    '162': 184,\n",
      "    '163': 185,\n",
      "    '164': 186,\n",
      "    '165': 187,\n",
      "    '166': 188,\n",
      "    '167': 189,\n",
      "    '168': 190,\n",
      "    '169': 191,\n",
      "    '17': 39,\n",
      "    '170': 192,\n",
      "    '171': 193,\n",
      "    '172': 194,\n",
      "    '173': 195,\n",
      "    '174': 196,\n",
      "    '175': 197,\n",
      "    '176': 198,\n",
      "    '177': 199,\n",
      "    '178': 200,\n",
      "    '179': 201,\n",
      "    '18': 40,\n",
      "    '180': 202,\n",
      "    '181': 203,\n",
      "    '182': 204,\n",
      "    '183': 205,\n",
      "    '184': 206,\n",
      "    '185': 207,\n",
      "    '186': 208,\n",
      "    '187': 209,\n",
      "    '188': 210,\n",
      "    '189': 211,\n",
      "    '19': 41,\n",
      "    '190': 212,\n",
      "    '191': 213,\n",
      "    '192': 214,\n",
      "    '193': 215,\n",
      "    '194': 216,\n",
      "    '195': 217,\n",
      "    '196': 218,\n",
      "    '197': 219,\n",
      "    '198': 220,\n",
      "    '199': 221,\n",
      "    '2': 24,\n",
      "    '20': 42,\n",
      "    '200': 222,\n",
      "    '201': 223,\n",
      "    '202': 224,\n",
      "    '203': 225,\n",
      "    '204': 226,\n",
      "    '205': 227,\n",
      "    '206': 228,\n",
      "    '207': 229,\n",
      "    '208': 230,\n",
      "    '209': 231,\n",
      "    '21': 43,\n",
      "    '210': 232,\n",
      "    '211': 233,\n",
      "    '212': 234,\n",
      "    '213': 235,\n",
      "    '214': 236,\n",
      "    '215': 237,\n",
      "    '216': 238,\n",
      "    '217': 239,\n",
      "    '218': 240,\n",
      "    '219': 241,\n",
      "    '22': 44,\n",
      "    '220': 242,\n",
      "    '221': 243,\n",
      "    '222': 244,\n",
      "    '223': 245,\n",
      "    '224': 246,\n",
      "    '225': 247,\n",
      "    '226': 248,\n",
      "    '227': 249,\n",
      "    '228': 250,\n",
      "    '229': 251,\n",
      "    '23': 45,\n",
      "    '230': 252,\n",
      "    '231': 253,\n",
      "    '232': 254,\n",
      "    '233': 255,\n",
      "    '234': 256,\n",
      "    '235': 257,\n",
      "    '236': 258,\n",
      "    '237': 259,\n",
      "    '238': 260,\n",
      "    '239': 261,\n",
      "    '24': 46,\n",
      "    '240': 262,\n",
      "    '241': 263,\n",
      "    '242': 264,\n",
      "    '243': 265,\n",
      "    '244': 266,\n",
      "    '245': 267,\n",
      "    '246': 268,\n",
      "    '247': 269,\n",
      "    '248': 270,\n",
      "    '249': 271,\n",
      "    '25': 47,\n",
      "    '250': 272,\n",
      "    '251': 273,\n",
      "    '252': 274,\n",
      "    '253': 275,\n",
      "    '254': 276,\n",
      "    '255': 277,\n",
      "    '256': 278,\n",
      "    '257': 279,\n",
      "    '258': 280,\n",
      "    '259': 281,\n",
      "    '26': 48,\n",
      "    '260': 282,\n",
      "    '261': 283,\n",
      "    '262': 284,\n",
      "    '263': 285,\n",
      "    '264': 286,\n",
      "    '265': 287,\n",
      "    '266': 288,\n",
      "    '267': 289,\n",
      "    '268': 290,\n",
      "    '269': 291,\n",
      "    '27': 49,\n",
      "    '270': 292,\n",
      "    '271': 293,\n",
      "    '272': 294,\n",
      "    '273': 295,\n",
      "    '274': 296,\n",
      "    '275': 297,\n",
      "    '276': 298,\n",
      "    '277': 299,\n",
      "    '278': 300,\n",
      "    '279': 301,\n",
      "    '28': 50,\n",
      "    '280': 302,\n",
      "    '281': 303,\n",
      "    '282': 304,\n",
      "    '283': 305,\n",
      "    '284': 306,\n",
      "    '285': 307,\n",
      "    '286': 308,\n",
      "    '287': 309,\n",
      "    '288': 310,\n",
      "    '289': 311,\n",
      "    '29': 51,\n",
      "    '290': 312,\n",
      "    '291': 313,\n",
      "    '292': 314,\n",
      "    '293': 315,\n",
      "    '294': 316,\n",
      "    '295': 317,\n",
      "    '296': 318,\n",
      "    '297': 319,\n",
      "    '298': 320,\n",
      "    '299': 321,\n",
      "    '3': 25,\n",
      "    '30': 52,\n",
      "    '300': 322,\n",
      "    '301': 323,\n",
      "    '302': 324,\n",
      "    '303': 325,\n",
      "    '304': 326,\n",
      "    '305': 327,\n",
      "    '306': 328,\n",
      "    '307': 329,\n",
      "    '308': 330,\n",
      "    '309': 331,\n",
      "    '31': 53,\n",
      "    '310': 332,\n",
      "    '311': 333,\n",
      "    '312': 334,\n",
      "    '313': 335,\n",
      "    '314': 336,\n",
      "    '315': 337,\n",
      "    '316': 338,\n",
      "    '317': 339,\n",
      "    '318': 340,\n",
      "    '319': 341,\n",
      "    '32': 54,\n",
      "    '320': 342,\n",
      "    '321': 343,\n",
      "    '322': 344,\n",
      "    '323': 345,\n",
      "    '324': 346,\n",
      "    '325': 347,\n",
      "    '326': 348,\n",
      "    '327': 349,\n",
      "    '328': 350,\n",
      "    '329': 351,\n",
      "    '33': 55,\n",
      "    '330': 352,\n",
      "    '331': 353,\n",
      "    '332': 354,\n",
      "    '333': 355,\n",
      "    '334': 356,\n",
      "    '335': 357,\n",
      "    '336': 358,\n",
      "    '337': 359,\n",
      "    '338': 360,\n",
      "    '339': 361,\n",
      "    '34': 56,\n",
      "    '340': 362,\n",
      "    '341': 363,\n",
      "    '342': 364,\n",
      "    '343': 365,\n",
      "    '344': 366,\n",
      "    '345': 367,\n",
      "    '346': 368,\n",
      "    '347': 369,\n",
      "    '348': 370,\n",
      "    '349': 371,\n",
      "    '35': 57,\n",
      "    '350': 372,\n",
      "    '351': 373,\n",
      "    '352': 374,\n",
      "    '353': 375,\n",
      "    '354': 376,\n",
      "    '355': 377,\n",
      "    '356': 378,\n",
      "    '357': 379,\n",
      "    '358': 380,\n",
      "    '359': 381,\n",
      "    '36': 58,\n",
      "    '360': 382,\n",
      "    '361': 383,\n",
      "    '362': 384,\n",
      "    '363': 385,\n",
      "    '364': 386,\n",
      "    '365': 387,\n",
      "    '366': 388,\n",
      "    '367': 389,\n",
      "    '368': 390,\n",
      "    '369': 391,\n",
      "    '37': 59,\n",
      "    '370': 392,\n",
      "    '371': 393,\n",
      "    '372': 394,\n",
      "    '373': 395,\n",
      "    '374': 396,\n",
      "    '375': 397,\n",
      "    '376': 398,\n",
      "    '377': 399,\n",
      "    '378': 400,\n",
      "    '379': 401,\n",
      "    '38': 60,\n",
      "    '380': 402,\n",
      "    '381': 403,\n",
      "    '382': 404,\n",
      "    '383': 405,\n",
      "    '384': 406,\n",
      "    '385': 407,\n",
      "    '386': 408,\n",
      "    '387': 409,\n",
      "    '388': 410,\n",
      "    '389': 411,\n",
      "    '39': 61,\n",
      "    '390': 412,\n",
      "    '391': 413,\n",
      "    '392': 414,\n",
      "    '393': 415,\n",
      "    '394': 416,\n",
      "    '395': 417,\n",
      "    '396': 418,\n",
      "    '397': 419,\n",
      "    '398': 420,\n",
      "    '399': 421,\n",
      "    '4': 26,\n",
      "    '40': 62,\n",
      "    '400': 422,\n",
      "    '401': 423,\n",
      "    '402': 424,\n",
      "    '403': 425,\n",
      "    '404': 426,\n",
      "    '405': 427,\n",
      "    '406': 428,\n",
      "    '407': 429,\n",
      "    '408': 430,\n",
      "    '409': 431,\n",
      "    '41': 63,\n",
      "    '410': 432,\n",
      "    '411': 433,\n",
      "    '412': 434,\n",
      "    '413': 435,\n",
      "    '414': 436,\n",
      "    '415': 437,\n",
      "    '416': 438,\n",
      "    '417': 439,\n",
      "    '418': 440,\n",
      "    '419': 441,\n",
      "    '42': 64,\n",
      "    '420': 442,\n",
      "    '421': 443,\n",
      "    '422': 444,\n",
      "    '423': 445,\n",
      "    '424': 446,\n",
      "    '425': 447,\n",
      "    '426': 448,\n",
      "    '427': 449,\n",
      "    '428': 450,\n",
      "    '429': 451,\n",
      "    '43': 65,\n",
      "    '430': 452,\n",
      "    '431': 453,\n",
      "    '432': 454,\n",
      "    '433': 455,\n",
      "    '434': 456,\n",
      "    '435': 457,\n",
      "    '436': 458,\n",
      "    '437': 459,\n",
      "    '438': 460,\n",
      "    '439': 461,\n",
      "    '44': 66,\n",
      "    '440': 462,\n",
      "    '441': 463,\n",
      "    '442': 464,\n",
      "    '443': 465,\n",
      "    '444': 466,\n",
      "    '445': 467,\n",
      "    '446': 468,\n",
      "    '447': 469,\n",
      "    '448': 470,\n",
      "    '449': 471,\n",
      "    '45': 67,\n",
      "    '450': 472,\n",
      "    '451': 473,\n",
      "    '452': 474,\n",
      "    '453': 475,\n",
      "    '454': 476,\n",
      "    '455': 477,\n",
      "    '456': 478,\n",
      "    '457': 479,\n",
      "    '458': 480,\n",
      "    '459': 481,\n",
      "    '46': 68,\n",
      "    '460': 482,\n",
      "    '461': 483,\n",
      "    '462': 484,\n",
      "    '463': 485,\n",
      "    '464': 486,\n",
      "    '465': 487,\n",
      "    '466': 488,\n",
      "    '467': 489,\n",
      "    '468': 490,\n",
      "    '469': 491,\n",
      "    '47': 69,\n",
      "    '470': 492,\n",
      "    '471': 493,\n",
      "    '472': 494,\n",
      "    '473': 495,\n",
      "    '474': 496,\n",
      "    '475': 497,\n",
      "    '476': 498,\n",
      "    '477': 499,\n",
      "    '478': 500,\n",
      "    '479': 501,\n",
      "    '48': 70,\n",
      "    '480': 502,\n",
      "    '481': 503,\n",
      "    '482': 504,\n",
      "    '483': 505,\n",
      "    '484': 506,\n",
      "    '485': 507,\n",
      "    '486': 508,\n",
      "    '487': 509,\n",
      "    '488': 510,\n",
      "    '489': 511,\n",
      "    '49': 71,\n",
      "    '490': 512,\n",
      "    '491': 513,\n",
      "    '492': 514,\n",
      "    '493': 515,\n",
      "    '494': 516,\n",
      "    '495': 517,\n",
      "    '496': 518,\n",
      "    '497': 519,\n",
      "    '498': 520,\n",
      "    '499': 521,\n",
      "    '5': 27,\n",
      "    '50': 72,\n",
      "    '500': 522,\n",
      "    '501': 523,\n",
      "    '502': 524,\n",
      "    '503': 525,\n",
      "    '504': 526,\n",
      "    '505': 527,\n",
      "    '506': 528,\n",
      "    '507': 529,\n",
      "    '508': 530,\n",
      "    '509': 531,\n",
      "    '51': 73,\n",
      "    '510': 532,\n",
      "    '511': 533,\n",
      "    '52': 74,\n",
      "    '53': 75,\n",
      "    '54': 76,\n",
      "    '55': 77,\n",
      "    '56': 78,\n",
      "    '57': 79,\n",
      "    '58': 80,\n",
      "    '59': 81,\n",
      "    '6': 28,\n",
      "    '60': 82,\n",
      "    '61': 83,\n",
      "    '62': 84,\n",
      "    '63': 85,\n",
      "    '64': 86,\n",
      "    '65': 87,\n",
      "    '66': 88,\n",
      "    '67': 89,\n",
      "    '68': 90,\n",
      "    '69': 91,\n",
      "    '7': 29,\n",
      "    '70': 92,\n",
      "    '71': 93,\n",
      "    '72': 94,\n",
      "    '73': 95,\n",
      "    '74': 96,\n",
      "    '75': 97,\n",
      "    '76': 98,\n",
      "    '77': 99,\n",
      "    '78': 100,\n",
      "    '79': 101,\n",
      "    '8': 30,\n",
      "    '80': 102,\n",
      "    '81': 103,\n",
      "    '82': 104,\n",
      "    '83': 105,\n",
      "    '84': 106,\n",
      "    '85': 107,\n",
      "    '86': 108,\n",
      "    '87': 109,\n",
      "    '88': 110,\n",
      "    '89': 111,\n",
      "    '9': 31,\n",
      "    '90': 112,\n",
      "    '91': 113,\n",
      "    '92': 114,\n",
      "    '93': 115,\n",
      "    '94': 116,\n",
      "    '95': 117,\n",
      "    '96': 118,\n",
      "    '97': 119,\n",
      "    '98': 120,\n",
      "    '99': 121,\n",
      "    '<->': 546,\n",
      "    '<.>': 545,\n",
      "    '<0>': 547,\n",
      "    '<1>': 548,\n",
      "    '<2>': 549,\n",
      "    '<3>': 550,\n",
      "    '<4>': 551,\n",
      "    '<5>': 552,\n",
      "    '<6>': 553,\n",
      "    '<7>': 554,\n",
      "    '<8>': 555,\n",
      "    '<9>': 556,\n",
      "    '<bos>': 20,\n",
      "    '<e>': 544,\n",
      "    '<edge_bi>': 17,\n",
      "    '<edge_in>': 15,\n",
      "    '<edge_jump>': 18,\n",
      "    '<edge_out>': 16,\n",
      "    '<eos>': 19,\n",
      "    '<gsum>': 14,\n",
      "    '<icl>': 2,\n",
      "    '<label_pad>': -100,\n",
      "    '<mask>': 1,\n",
      "    '<new>': 21,\n",
      "    '<sep>': 3,\n",
      "    'molecule#edge#0': 740,\n",
      "    'molecule#edge#0#0': 743,\n",
      "    'molecule#edge#0#1': 744,\n",
      "    'molecule#edge#0#2': 745,\n",
      "    'molecule#edge#0#3': 746,\n",
      "    'molecule#edge#0#4': 747,\n",
      "    'molecule#edge#1': 741,\n",
      "    'molecule#edge#1#0': 748,\n",
      "    'molecule#edge#1#1': 749,\n",
      "    'molecule#edge#1#2': 750,\n",
      "    'molecule#edge#1#3': 751,\n",
      "    'molecule#edge#1#4': 752,\n",
      "    'molecule#edge#1#5': 753,\n",
      "    'molecule#edge#2': 742,\n",
      "    'molecule#edge#2#0': 754,\n",
      "    'molecule#edge#2#1': 755,\n",
      "    'molecule#node#0': 557,\n",
      "    'molecule#node#0#0': 566,\n",
      "    'molecule#node#0#1': 567,\n",
      "    'molecule#node#0#10': 568,\n",
      "    'molecule#node#0#100': 569,\n",
      "    'molecule#node#0#101': 570,\n",
      "    'molecule#node#0#102': 571,\n",
      "    'molecule#node#0#103': 572,\n",
      "    'molecule#node#0#104': 573,\n",
      "    'molecule#node#0#105': 574,\n",
      "    'molecule#node#0#106': 575,\n",
      "    'molecule#node#0#107': 576,\n",
      "    'molecule#node#0#108': 577,\n",
      "    'molecule#node#0#109': 578,\n",
      "    'molecule#node#0#11': 579,\n",
      "    'molecule#node#0#110': 580,\n",
      "    'molecule#node#0#111': 581,\n",
      "    'molecule#node#0#112': 582,\n",
      "    'molecule#node#0#113': 583,\n",
      "    'molecule#node#0#114': 584,\n",
      "    'molecule#node#0#115': 585,\n",
      "    'molecule#node#0#116': 586,\n",
      "    'molecule#node#0#117': 587,\n",
      "    'molecule#node#0#118': 588,\n",
      "    'molecule#node#0#12': 589,\n",
      "    'molecule#node#0#13': 590,\n",
      "    'molecule#node#0#14': 591,\n",
      "    'molecule#node#0#15': 592,\n",
      "    'molecule#node#0#16': 593,\n",
      "    'molecule#node#0#17': 594,\n",
      "    'molecule#node#0#18': 595,\n",
      "    'molecule#node#0#19': 596,\n",
      "    'molecule#node#0#2': 597,\n",
      "    'molecule#node#0#20': 598,\n",
      "    'molecule#nod ......\n",
      "label token id to be converted to -100 is {2}\n"
     ]
    }
   ],
   "source": [
    "add_eos = False\n",
    "rank = 0\n",
    "stack_method = \"short\"\n",
    "# 1.3 build vocab and then init tokenizer from the tokenization config\n",
    "tokenizer_cls = getattr(tokenizer, tokenizer_config[\"tokenizer_class\"]) # StackGSTTokenizer, custom defined\n",
    "gtokenizer = tokenizer_cls(\n",
    "    tokenizer_config, add_eos=add_eos, stack_method=stack_method # instantiate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.data.tokenizer.StackedGSTTokenizer object at 0x7faa317c22b0>\n"
     ]
    }
   ],
   "source": [
    "print(gtokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./zhang_test/model_config.pkl\", \"rb\") as file:  # \"rb\" mode for reading binary\n",
    "    config = pickle.load(file)\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_deepspeed = True\n",
    "\n",
    "# # 2.2 create model\n",
    "# if use_deepspeed:\n",
    "#     deepspeed.init_distributed(\n",
    "#         dist_backend=\"nccl\", rank=rank, world_size=world_size\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT Applying dropout in backbone transformer\n",
      "Next-token-prediction changed to next/masked-13-tokens-prediction!\n",
      "trainable params: 37751808 || all params: 37751808 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "model = GraphModel(config)\n",
    "\n",
    "\n",
    "# model.gradient_checkpointing_enable()\n",
    "# silence the warnings. Please re-enable for inference!\n",
    "model.config.use_cache = False\n",
    "print_trainable_parameters(model) # 235368960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from ckp /datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1/epoch_51\n",
      "inar:  [Errno 2] No such file or directory: '/datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1/epoch_51/model.pt'\n",
      "Processing zero checkpoint '/datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1/epoch_51/global_step48830'\n",
      "Detected checkpoint of type zero stage 2, world_size: 1\n",
      "Parsing checkpoint created by deepspeed==0.15.1\n",
      "Reconstructed fp32 state dict with 77 params 37751808 elements\n",
      "[2025-05-16 16:37:45.130730] load ckp using DeepSpeed API `get_fp32_state_dict_from_zero_checkpoint`\n",
      "[2025-05-16 16:37:45.164076] init model params using pytorch `load_state_dict`\n",
      "missing keys: []\n",
      "unexpected_keys: []\n",
      "After loading weights from ckp:\n",
      "GraphGPTConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 20,\n",
      "  \"causal_attention\": true,\n",
      "  \"cls_token_id\": null,\n",
      "  \"dropout\": 0,\n",
      "  \"embed_dim\": 0,\n",
      "  \"embed_pdrop\": 0,\n",
      "  \"eos_token_id\": 19,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_scale_init_value\": 0,\n",
      "  \"loss_type\": null,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"mlp\": [],\n",
      "  \"mlp_pdrop\": 0,\n",
      "  \"model_type\": \"graphgpt\",\n",
      "  \"next_n_token\": 13,\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_neg\": null,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"path_pdrop\": 0,\n",
      "  \"pooling_method\": \"last\",\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000,\n",
      "  \"stack_method\": \"short\",\n",
      "  \"stacked_feat\": 13,\n",
      "  \"stacked_feat_agg_method\": \"gated\",\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 756\n",
      "}\n",
      "\n",
      "model-type: torch.float32\n",
      "\n",
      "GraphGPTCausal(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(756, 512, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-7): 8 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (up_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (down_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (act_fn): GELUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=756, bias=False)\n",
      "  (stacked_feat_agg): StackedFeatAggregation(stacked_feat=13, hidden_size=512)\n",
      "  (next_n_token_head): Linear(in_features=512, out_features=6656, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.21 load from ckp IF provided existing ckp and NOT resume from the ckp\n",
    "ckp, _ = misc_utils.get_latest_ckp(pretrain_cpt)\n",
    "print(f\"Loading pretrained weights from ckp {ckp}\")\n",
    "try:\n",
    "    # fn_model = os.path.join(ckp, \"../model_ema_best.pt\")\n",
    "    # if not os.path.isfile(fn_model):\n",
    "    fn_model = os.path.join(ckp, \"model.pt\")\n",
    "    stat_dict = torch.load(fn_model)\n",
    "    stat_dict = {\n",
    "        (k[7:] if k.startswith(\"module.\") else k): v for k, v in stat_dict.items()\n",
    "    }\n",
    "    print(f\"[{datetime.now()}] load ckp using torch API from:\\n{fn_model}\")\n",
    "except Exception as inst:\n",
    "    # print(type(inst))\n",
    "    # print(inst.args)\n",
    "    print(\"inar: \", inst)\n",
    "    from deepspeed.utils.zero_to_fp32 import (\n",
    "        get_fp32_state_dict_from_zero_checkpoint,\n",
    "    )\n",
    "    stat_dict = get_fp32_state_dict_from_zero_checkpoint(ckp)\n",
    "    print(\n",
    "        f\"[{datetime.now()}] load ckp using DeepSpeed API `get_fp32_state_dict_from_zero_checkpoint`\"\n",
    "    )\n",
    "\n",
    "for key in list(stat_dict.keys()):\n",
    "    if (\"score\" in key) and skip_keys:\n",
    "        stat_dict.pop(key)\n",
    "        print(f\"pop key {key} in stat_dict!\")\n",
    "missing_keys, unexpected_keys = model.load_state_dict(stat_dict, strict=True)\n",
    "print(\n",
    "    f\"[{datetime.now()}] init model params using pytorch `load_state_dict`\\n\"\n",
    "    f\"missing keys: {missing_keys}\\n\"\n",
    "    f\"unexpected_keys: {unexpected_keys}\\n\"\n",
    "    f\"After loading weights from ckp:\\n{model.config}\\nmodel-type: {model.dtype}\\n\\n{model}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"device: {device}\")\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset PCQM4Mv2 ...\n",
      "\n",
      "dataset._data -> Data(edge_index=[2, 109093626], edge_attr=[109093626, 3], x=[52970652, 9], y=[3746620])\n",
      "\n",
      "Raw indices: 3378606, Removed indices: 0, New indices: 3378606\n",
      "\n",
      "Raw indices: 73545, Removed indices: 0, New indices: 73545\n",
      "Using all valid data as valid: 73545, and last half of valid data as test: 36773!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "\n",
      "[2025-05-16 16:38:06.442730] NOT RESET samples of GraphsMapDataset of 3378606 graphs for epoch None!\n",
      "idx_tuple: None\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "\n",
      "[2025-05-16 16:38:06.479696] NOT RESET samples of GraphsMapDataset of 73545 graphs for epoch None!\n",
      "idx_tuple: None\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "\n",
      "[2025-05-16 16:38:06.496574] NOT RESET samples of GraphsMapDataset of 36773 graphs for epoch None!\n",
      "idx_tuple: None\n",
      "Split dataset based on given train/valid/test index!\n",
      "Train: 3378606, Valid: 73545, Test: 36773!\n",
      "(3561983, Data(edge_index=[2, 34], edge_attr=[34, 3], x=[16, 9], y=[1], num_nodes=16, idx=3561983, idx_of_ds=0))\n"
     ]
    }
   ],
   "source": [
    "# 1.2 get graph dataset\n",
    "train_dataset, valid_dataset, test_dataset, raw_dataset = read_dataset(\n",
    "    name=tokenizer_config[\"dataset\"],   # PCQM4Mv2\n",
    "    # for local data file reading\n",
    "    data_dir=data_dir,   # './data/OGB'\n",
    "    sampling_config=tokenizer_config[\"sampling\"],    # None\n",
    "    # for odps data reading\n",
    "    table=tables,   # \"\"\n",
    "    edge_dim=tokenizer_config[\"semantics\"][\"edge\"][\"dim\"],    # 3\n",
    "    node_dim=tokenizer_config[\"semantics\"][\"node\"][\"dim\"],    # 9\n",
    "    mode=\"train\",\n",
    "    # general\n",
    "    # pretrain_mode=True,\n",
    "    return_valid_test=True,\n",
    "    ensemble_datasets=tokenizer_config.get(\"ensemble_datasets\", []),    # []\n",
    ")\n",
    "reset_samples_per_epoch = (   # what is this  # None for PCQM4Mv2\n",
    "    test_dataset.reset_samples_per_epoch\n",
    "    if hasattr(test_dataset, \"reset_samples_per_epoch\")\n",
    "    else False\n",
    ")\n",
    "if isinstance(test_dataset, IterableDataset):\n",
    "    print(next(iter(test_dataset))) \n",
    "else: # True\n",
    "    idx = test_dataset.sampler[0] # (0, Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1, 1], num_nodes=18, idx=0, idx_of_ds=0))\n",
    "    print(test_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.data.dataset_map.GraphsMapDataset object at 0x7faa6a3291f0>\n",
      "length of test dataset: 36773 length of train dataset: 3378606 length of valid dataset: 73545\n",
      "(1, Data(edge_index=[2, 34], edge_attr=[34, 3], x=[17, 9], y=[1], num_nodes=17, idx=1, idx_of_ds=0))\n",
      "(2, Data(edge_index=[2, 32], edge_attr=[32, 3], x=[16, 9], y=[1], num_nodes=16, idx=2, idx_of_ds=0))\n",
      "####################################################################################################\n",
      "example\n",
      "edge_index:  tensor([[12, 13, 13,  2,  2,  8,  8, 16, 16,  0,  0,  6, 16, 14, 14,  4,  4,  3,\n",
      "          3, 10, 10,  5,  5, 15, 15,  1,  1,  7,  1, 11, 15,  9,  3,  2],\n",
      "        [13, 12,  2, 13,  8,  2, 16,  8,  0, 16,  6,  0, 14, 16,  4, 14,  3,  4,\n",
      "         10,  3,  5, 10, 15,  5,  1, 15,  7,  1, 11,  1,  9, 15,  2,  3]])\n",
      "edge_attr:  tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 2, 1],\n",
      "        [1, 2, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1]])\n",
      "x:  tensor([[6, 0, 3, 5, 0, 0, 1, 0, 0],\n",
      "        [7, 0, 2, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 0, 0],\n",
      "        [7, 0, 2, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 0, 0],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
      "        [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0]])\n",
      "y:  tensor([4.4110])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)\n",
    "print('length of test dataset:', len(test_dataset), 'length of train dataset:', len(train_dataset), 'length of valid dataset:', len(valid_dataset))\n",
    "print(test_dataset[1])\n",
    "print(test_dataset[2])\n",
    "print(\"#\" * 100)\n",
    "print(\"example\")\n",
    "print(\"edge_index: \", test_dataset[1][1].edge_index)\n",
    "print(\"edge_attr: \", test_dataset[1][1].edge_attr)\n",
    "print(\"x: \", test_dataset[1][1].x)\n",
    "print(\"y: \", test_dataset[1][1].y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=CCN(C=Cc1ccccc1C)C(C)=O\n"
     ]
    }
   ],
   "source": [
    "graph_test = test_dataset[2][1]\n",
    "from src.utils.my_utiles import graph2smiles\n",
    "smiles = graph2smiles(graph_test.edge_index, graph_test.edge_attr, graph_test.x)\n",
    "print(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['edge_index', 'edge_attr', 'x', 'num_nodes'])\n",
      "(2, 26)\n",
      "(26, 3)\n",
      "(13, 9)\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import smiles2graph\n",
    "smiles = \"CCO\"\n",
    "graph = smiles2graph(\"CC(=O)OC1=CC=CC=C1C(=O)O\")\n",
    "print(graph.keys())\n",
    "print(graph['edge_index'].shape)\n",
    "print(graph['edge_attr'].shape)\n",
    "print(graph['x'].shape)\n",
    "print(graph['num_nodes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 26])\n",
      "torch.Size([26, 3])\n",
      "torch.Size([13, 9])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import graph_to_torch_geometric\n",
    "graph = graph_to_torch_geometric(graph)\n",
    "print(graph['edge_index'].shape)\n",
    "print(graph['edge_attr'].shape)\n",
    "print(graph['x'].shape)\n",
    "print(graph['num_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC(=O)Oc1ccccc1C(=O)O\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import graph2smiles\n",
    "smiles = graph2smiles(graph.edge_index, graph.edge_attr, graph.x)\n",
    "print(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting tokenization results!\n",
      "Tokenize graph:\n",
      "Data(edge_index=[2, 32], edge_attr=[32, 3], x=[16, 9], y=[1], num_nodes=16, idx=2, idx_of_ds=0)\n",
      "[Warning] Set eos_idx to 100000000 for task pretrain!\n",
      "\n",
      "Tokens:\n",
      "[['165',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0',\n",
      "  'molecule#edge#1',\n",
      "  'molecule#edge#2'],\n",
      " ['166',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['167',\n",
      "  'molecule#node#0#7',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#1',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['166',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['168',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#3',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['166',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['165',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['169',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['170',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['171',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['170',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['169',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['165',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['172',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['173',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#2',\n",
      "  'molecule#edge#2#1'],\n",
      " ['174',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['175',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['176',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#3',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['175',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['177',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['178',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['179',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['180',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['174',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1']]\n",
      "Labels:\n",
      "[['166',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['167',\n",
      "  'molecule#node#0#7',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#1',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['166',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['168',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#3',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['166',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['165',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['169',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['170',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['171',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['170',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['169',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['165',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['172',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['173',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#2',\n",
      "  'molecule#edge#2#1'],\n",
      " ['174',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['175',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['176',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#3',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['175',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['177',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['178',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['179',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['180',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['174',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>']]\n",
      "embed:[]\n",
      "\n",
      "Inputs for model:\n",
      "{'attention_mask': [1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1],\n",
      " 'embed': array([], shape=(24, 0), dtype=float64),\n",
      " 'input_ids': [[187,\n",
      "                641,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                740,\n",
      "                741,\n",
      "                742],\n",
      "               [188,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                755],\n",
      "               [189,\n",
      "                652,\n",
      "                685,\n",
      "                691,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                744,\n",
      "                748,\n",
      "                755],\n",
      "               [188,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                744,\n",
      "                748,\n",
      "                755],\n",
      "               [190,\n",
      "                630,\n",
      "                685,\n",
      "                696,\n",
      "                709,\n",
      "                717,\n",
      "                724,\n",
      "                732,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [188,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [187,\n",
      "                641,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                755],\n",
      "               [191,\n",
      "                630,\n",
      "                685,\n",
      "                696,\n",
      "                709,\n",
      "                716,\n",
      "                724,\n",
      "                732,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [192,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [193,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                716,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                744,\n",
      "                748,\n",
      "                754],\n",
      "               [192,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                744,\n",
      "                748,\n",
      "                754],\n",
      "               [191,\n",
      "                630,\n",
      "                685,\n",
      "                696,\n",
      "                709,\n",
      "                716,\n",
      "                724,\n",
      "                732,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [187,\n",
      "                641,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [194,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                755],\n",
      "               [195,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                736,\n",
      "                738,\n",
      "                744,\n",
      "                750,\n",
      "                755],\n",
      "               [196,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                743,\n",
      "                748,\n",
      "                755],\n",
      "               [197,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755],\n",
      "               [198,\n",
      "                630,\n",
      "                685,\n",
      "                696,\n",
      "                709,\n",
      "                717,\n",
      "                724,\n",
      "                732,\n",
      "                736,\n",
      "                738,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [197,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                743,\n",
      "                748,\n",
      "                754],\n",
      "               [199,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755],\n",
      "               [200,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755],\n",
      "               [201,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755],\n",
      "               [202,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                715,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755],\n",
      "               [196,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755]],\n",
      " 'labels': [[188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 755],\n",
      "            [189, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "            [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "            [190, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "            [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 754],\n",
      "            [187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 755],\n",
      "            [191, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "            [192, 630, 685, 695, 709, 715, 724, 731, 736, 738, 743, 748, 754],\n",
      "            [193, 630, 685, 695, 709, 716, 724, 731, 736, 738, 744, 748, 754],\n",
      "            [192, 630, 685, 695, 709, 715, 724, 731, 736, 738, 744, 748, 754],\n",
      "            [191, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "            [187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 754],\n",
      "            [194, 630, 685, 695, 709, 715, 724, 731, 736, 738, 743, 748, 755],\n",
      "            [195, 630, 685, 695, 709, 715, 724, 731, 736, 738, 744, 750, 755],\n",
      "            [196, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 755],\n",
      "            [197, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [198, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "            [197, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "            [199, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [200, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [201, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [202, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [196, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]],\n",
      " 'position_ids': [0,\n",
      "                  1,\n",
      "                  2,\n",
      "                  3,\n",
      "                  4,\n",
      "                  5,\n",
      "                  6,\n",
      "                  7,\n",
      "                  8,\n",
      "                  9,\n",
      "                  10,\n",
      "                  11,\n",
      "                  12,\n",
      "                  13,\n",
      "                  14,\n",
      "                  15,\n",
      "                  16,\n",
      "                  17,\n",
      "                  18,\n",
      "                  19,\n",
      "                  20,\n",
      "                  21,\n",
      "                  22,\n",
      "                  23]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_graph = graph_test\n",
    "from src.utils.my_utiles import graph2token2input\n",
    "import numpy as np\n",
    "token, label, embed, inputs = graph2token2input(example_graph, gtokenizer)\n",
    "\n",
    "print(\n",
    "    f\"\\nTokens:\\n{pformat(token)}\\nLabels:\\n{pformat(label)}\\nembed:{np.array(embed)}\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Inputs for model:\\n{pformat(inputs)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n",
      "input_ids: torch.Size([1, 24, 13])\n",
      "position_ids: torch.Size([1, 24])\n",
      "labels: torch.Size([1, 24, 13])\n",
      "attention_mask: torch.Size([1, 24])\n",
      "embed: torch.Size([1, 24, 0])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import convert_to_tensors\n",
    "\n",
    "tensor_inputs = convert_to_tensors(inputs)\n",
    "print(tensor_inputs.keys())\n",
    "\n",
    "print(\"input_ids:\", tensor_inputs[\"input_ids\"].shape)\n",
    "print(\"position_ids:\", tensor_inputs[\"position_ids\"].shape)\n",
    "print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "print(\"attention_mask:\", tensor_inputs[\"attention_mask\"].shape)\n",
    "print(\"embed:\", tensor_inputs[\"embed\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 740, 741, 742],\n",
      "         [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 755],\n",
      "         [189, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "         [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "         [190, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 755],\n",
      "         [191, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [192, 630, 685, 695, 709, 715, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [193, 630, 685, 695, 709, 716, 724, 731, 736, 738, 744, 748, 754],\n",
      "         [192, 630, 685, 695, 709, 715, 724, 731, 736, 738, 744, 748, 754],\n",
      "         [191, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [194, 630, 685, 695, 709, 715, 724, 731, 736, 738, 743, 748, 755],\n",
      "         [195, 630, 685, 695, 709, 715, 724, 731, 736, 738, 744, 750, 755],\n",
      "         [196, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 755],\n",
      "         [197, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [198, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [197, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [199, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [200, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [201, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [202, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [196, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755]]])\n",
      "tensor([[[188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 755],\n",
      "         [189, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "         [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "         [190, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [188, 630, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 755],\n",
      "         [191, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [192, 630, 685, 695, 709, 715, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [193, 630, 685, 695, 709, 716, 724, 731, 736, 738, 744, 748, 754],\n",
      "         [192, 630, 685, 695, 709, 715, 724, 731, 736, 738, 744, 748, 754],\n",
      "         [191, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [187, 641, 685, 695, 709, 714, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [194, 630, 685, 695, 709, 715, 724, 731, 736, 738, 743, 748, 755],\n",
      "         [195, 630, 685, 695, 709, 715, 724, 731, 736, 738, 744, 750, 755],\n",
      "         [196, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 755],\n",
      "         [197, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [198, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [197, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [199, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [200, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [201, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [202, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [196, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_inputs[\"input_ids\"])\n",
    "print(tensor_inputs[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 24, 13])\n",
      "position_ids: torch.Size([1, 24])\n",
      "labels: torch.Size([1, 24, 13])\n",
      "attention_mask: torch.Size([1, 24])\n",
      "embed: torch.Size([1, 24, 0])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids:\", tensor_inputs[\"input_ids\"].shape)\n",
    "print(\"position_ids:\", tensor_inputs[\"position_ids\"].shape)\n",
    "print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "print(\"attention_mask:\", tensor_inputs[\"attention_mask\"].shape)\n",
    "print(\"embed:\", tensor_inputs[\"embed\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(1, 24, 0), dtype=torch.float64)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_inputs[\"embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6440\n",
      "Cc1ccc(C2Cc3cnccc3NC2=O)cc1\n",
      "Inspecting tokenization results!\n",
      "Tokenize graph:\n",
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1], num_nodes=18, idx=0, idx_of_ds=0)\n",
      "token (25, 13)\n",
      "label (25, 13)\n",
      "embed (25, 0)\n",
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n",
      "input_ids (25, 13)\n",
      "position_ids (25,)\n",
      "labels (25, 13)\n",
      "attention_mask (25,)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import graph2token2input_generation\n",
    "# smiles = \"CCO\" # \"CC(=O)OC1=CC=CC=C1C(=O)O\"\\\n",
    "random_index = np.random.randint(0, len(test_dataset))  # Upper bound is exclusive\n",
    "print(random_index)\n",
    "random_index = 0\n",
    "graph = test_dataset[random_index][1]\n",
    "# graph = graph_to_torch_geometric(graph)\n",
    "smiles2 = graph2smiles(graph.edge_index, graph.edge_attr, graph.x)\n",
    "example_graph = graph\n",
    "print(smiles2)\n",
    "\n",
    "num_input, max_length = 5, 40\n",
    "token, label, embed, inputs = graph2token2input(graph, gtokenizer)\n",
    "print('token', np.array(token).shape)\n",
    "print('label', np.array(label).shape)\n",
    "print('embed', np.array(embed).shape)\n",
    "print(inputs.keys())\n",
    "print('input_ids', np.array(inputs[\"input_ids\"]).shape)\n",
    "print('position_ids', np.array(inputs[\"position_ids\"]).shape)\n",
    "print('labels', np.array(inputs[\"labels\"]).shape)\n",
    "print('attention_mask', np.array(inputs[\"attention_mask\"]).shape)\n",
    "# print('embed', np.array(inputs[\"embed\"]).shape)\n",
    "print(inputs[\"attention_mask\"])\n",
    "tensor_inputs = convert_to_tensors(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CausalLMOutputWithPast(loss=tensor(0.1313, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.5467, -0.6913, -0.7591,  ..., -0.9735,  0.7295,  0.1214],\n",
      "        [-8.3267, -8.2283, -8.2161,  ..., -8.1347, -3.2014, -3.1003],\n",
      "        [-4.2555, -4.6625, -4.4946,  ..., -4.6253, -0.9444, -1.0318],\n",
      "        ...,\n",
      "        [-0.1751,  0.1436, -0.4383,  ..., -0.6150,  1.7899,  0.0686],\n",
      "        [ 2.2697,  2.6892,  2.9154,  ...,  2.7431,  3.2211,  0.5504],\n",
      "        [-1.2200, -1.3780, -0.9202,  ..., -1.5514,  4.1868,  3.4425]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>), past_key_values=None, hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data = tensor_inputs\n",
    "input_ids = data[\"input_ids\"].to(device)\n",
    "# print(input_ids)\n",
    "attention_mask = data[\"attention_mask\"].to(device)\n",
    "labels = data[\"labels\"].to(device)\n",
    "inputs_raw_embeds = None\n",
    "if embed_dim > 0: # in tokenizer config\n",
    "    inputs_raw_embeds = data[\"embed\"].to(device)\n",
    "print(inputs_raw_embeds)\n",
    "output = model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    labels=labels,\n",
    "    inputs_raw_embeds=inputs_raw_embeds,\n",
    ")  # Perform a single forward pass.\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "# print(\"output:\", output.keys())\n",
    "# print(\"output:\", output[\"logits\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_labels = torch.argmax(output[\"logits\"], dim=-1) \n",
    "# reshaped_labels = predicted_labels.view(*tensor_inputs[\"labels\"].shape)\n",
    "# print(\"labels:\", tensor_inputs[\"labels\"])\n",
    "# print(\"predicted_labels:\", reshaped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # File path to your vocabulary file\n",
    "# vocab_file_path = \"/datalake/datastore1/yang/graph-gpt/data/OGB/pcqm4m-v2/vocab512_stacked\"\n",
    "\n",
    "# from src.utils.my_utiles import load_vocab\n",
    "\n",
    "# vocab = load_vocab(vocab_file_path)\n",
    "\n",
    "# from src.utils.my_utiles import convert_labels_to_tokens\n",
    "# # Example usage\n",
    "# # Assuming `reshaped_labels` contains the predicted label IDs of shape [1, 24, 13]\n",
    "# tokens = convert_labels_to_tokens(reshaped_labels, vocab)\n",
    "\n",
    "# # Optional: Reshape tokens back to the original structure for visualization\n",
    "# tokens_reshaped = [\n",
    "#     [tokens[i * 13 + j] for j in range(13)] for i in range(tensor_inputs[\"labels\"].shape[1])\n",
    "# ]\n",
    "\n",
    "# print(reshaped_labels.shape)\n",
    "# # Print tokens\n",
    "# print(np.array(tokens_reshaped).shape)\n",
    "# pprint(tokens_reshaped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873\n",
      "Cc1ccc(C2Cc3cnccc3NC2=O)cc1\n",
      "Inspecting tokenization results!\n",
      "Tokenize graph:\n",
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1], num_nodes=18, idx=0, idx_of_ds=0)\n",
      "token (5, 13)\n",
      "label (25, 13)\n",
      "embed (5, 0)\n",
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n",
      "input_ids (5, 13)\n",
      "position_ids (5,)\n",
      "labels (25, 13)\n",
      "attention_mask (5,)\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import graph2token2input_generation\n",
    "# smiles = \"CCO\" # \"CC(=O)OC1=CC=CC=C1C(=O)O\"\\\n",
    "random_index = np.random.randint(0, len(test_dataset))  # Upper bound is exclusive\n",
    "print(random_index)\n",
    "random_index = 0\n",
    "graph = test_dataset[random_index][1]\n",
    "# graph = graph_to_torch_geometric(graph)\n",
    "smiles2 = graph2smiles(graph.edge_index, graph.edge_attr, graph.x)\n",
    "example_graph = graph\n",
    "print(smiles2)\n",
    "\n",
    "num_input, max_length = 5, 40\n",
    "token, label, embed, inputs = graph2token2input_generation(graph, gtokenizer, num_input, max_length)\n",
    "print('token', np.array(token).shape)\n",
    "print('label', np.array(label).shape)\n",
    "print('embed', np.array(embed).shape)\n",
    "print(inputs.keys())\n",
    "print('input_ids', np.array(inputs[\"input_ids\"]).shape)\n",
    "print('position_ids', np.array(inputs[\"position_ids\"]).shape)\n",
    "print('labels', np.array(inputs[\"labels\"]).shape)\n",
    "print('attention_mask', np.array(inputs[\"attention_mask\"]).shape)\n",
    "# print('embed', np.array(inputs[\"embed\"]).shape)\n",
    "print(inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(token)\n",
    "# pprint(label)\n",
    "# pprint(inputs[\"input_ids\"])\n",
    "# pprint(inputs[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_inputs = convert_to_tensors(inputs)\n",
    "# print(tensor_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# output_ids = model.generate(\n",
    "#     input_ids=tensor_inputs[\"input_ids\"].to(device) ,          # Input token IDs\n",
    "#     attention_mask=tensor_inputs[\"attention_mask\"].to(device),  # Pass the attention mask\n",
    "#     position_ids=tensor_inputs[\"position_ids\"].to(device),      # Pass the position IDs\n",
    "#     max_length=20,                # Maximum generation length\n",
    "#     do_sample=True,               # Enable sampling\n",
    "#     temperature=0.7               # Temperature for randomness\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test generation my defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31740\n",
      "Cc1ccc(C2Cc3cnccc3NC2=O)cc1\n",
      "Inspecting tokenization results!\n",
      "Tokenize graph:\n",
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1], num_nodes=18, idx=0, idx_of_ds=0)\n",
      "token (2, 13)\n",
      "label (25, 13)\n",
      "embed (2, 0)\n",
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n",
      "input_ids (2, 13)\n",
      "position_ids (2,)\n",
      "labels (25, 13)\n",
      "attention_mask (2,)\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import graph2token2input_generation\n",
    "# smiles = \"CCO\" # \"CC(=O)OC1=CC=CC=C1C(=O)O\"\\\n",
    "random_index = np.random.randint(0, len(test_dataset))  # Upper bound is exclusive\n",
    "print(random_index)\n",
    "random_index = 0\n",
    "graph = test_dataset[random_index][1]\n",
    "# graph = graph_to_torch_geometric(graph)\n",
    "smiles2 = graph2smiles(graph.edge_index, graph.edge_attr, graph.x)\n",
    "example_graph = graph\n",
    "print(smiles2)\n",
    "\n",
    "num_input, max_length = 2, 40\n",
    "token, label, embed, inputs = graph2token2input_generation(graph, gtokenizer, num_input, max_length)\n",
    "print('token', np.array(token).shape)\n",
    "print('label', np.array(label).shape)\n",
    "print('embed', np.array(embed).shape)\n",
    "print(inputs.keys())\n",
    "print('input_ids', np.array(inputs[\"input_ids\"]).shape)\n",
    "print('position_ids', np.array(inputs[\"position_ids\"]).shape)\n",
    "print('labels', np.array(inputs[\"labels\"]).shape)\n",
    "print('attention_mask', np.array(inputs[\"attention_mask\"]).shape)\n",
    "# print('embed', np.array(inputs[\"embed\"]).shape)\n",
    "print(inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_inputs = convert_to_tensors(inputs)\n",
    "# print(tensor_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 2, 13])\n",
      "position_ids: torch.Size([1, 2])\n",
      "labels: torch.Size([1, 25, 13])\n",
      "attention_mask: torch.Size([1, 2])\n",
      "embed: torch.Size([1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids:\", tensor_inputs[\"input_ids\"].shape)\n",
    "print(\"position_ids:\", tensor_inputs[\"position_ids\"].shape)\n",
    "print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "print(\"attention_mask:\", tensor_inputs[\"attention_mask\"].shape)\n",
    "print(\"embed:\", tensor_inputs[\"embed\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "generated = model.generate_packed(\n",
    "    input_ids=tensor_inputs[\"input_ids\"].to(device),\n",
    "    attention_mask=tensor_inputs[\"attention_mask\"].to(device),\n",
    "    max_new_tokens = 30,\n",
    "    temperature = 1,\n",
    "    top_k = 50,\n",
    "    eos_token_id = 19,\n",
    "    pad_token_id = 0,\n",
    "    entire_context = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 740, 741, 742],\n",
       "         [140, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [141, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [142, 652, 685, 695, 709, 714, 724, 732, 736, 739, 743, 748, 755],\n",
       "         [143, 630, 685, 696, 709, 716, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [144, 630, 685, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [145, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
       "         [146, 641, 685, 694, 709, 716, 724, 731, 736, 738, 743, 748, 754],\n",
       "         [145, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
       "         [144, 630, 685, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [147, 630, 685, 696, 709, 716, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [142, 641, 685, 695, 709, 714, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [141, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
       "         [148, 630, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [149, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [150, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [ 19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_zero_mask = (generated.sum(dim=-1) != 0)\n",
    "# print(non_zero_mask.shape)\n",
    "# generated = generated[non_zero_mask.any(dim=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 740, 741, 742],\n",
       "         [140, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [141, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [142, 652, 685, 695, 709, 714, 724, 732, 736, 739, 743, 748, 755],\n",
       "         [143, 630, 685, 696, 709, 716, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [144, 630, 685, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [145, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
       "         [146, 641, 685, 694, 709, 716, 724, 731, 736, 738, 743, 748, 754],\n",
       "         [145, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
       "         [144, 630, 685, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [147, 630, 685, 696, 709, 716, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [142, 641, 685, 695, 709, 714, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [141, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
       "         [148, 630, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [149, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [150, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [ 19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[140, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [141, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [142, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [143, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [144, 641, 685, 694, 709, 714, 725, 731, 736, 739, 743, 748, 755],\n",
       "         [145, 630, 685, 695, 709, 714, 724, 731, 736, 739, 743, 748, 755],\n",
       "         [146, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
       "         [145, 630, 685, 695, 709, 714, 724, 731, 736, 739, 744, 748, 755],\n",
       "         [147, 630, 687, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [148, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
       "         [149, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [150, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [151, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [152, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
       "         [151, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
       "         [153, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [154, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [148, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [147, 630, 687, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
       "         [155, 630, 685, 695, 709, 715, 725, 732, 736, 739, 743, 748, 754],\n",
       "         [156, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
       "         [143, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [156, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
       "         [ 19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19]]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_inputs[\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 13])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_inputs[\"labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 13])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 740, 741, 742],\n",
      "         [140, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [141, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [142, 652, 685, 695, 709, 714, 724, 732, 736, 739, 743, 748, 755],\n",
      "         [143, 630, 685, 696, 709, 716, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [144, 630, 685, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [145, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [146, 641, 685, 694, 709, 716, 724, 731, 736, 738, 743, 748, 754],\n",
      "         [145, 630, 685, 696, 709, 716, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [144, 630, 685, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [147, 630, 685, 696, 709, 716, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [142, 641, 685, 695, 709, 714, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [141, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [148, 630, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [149, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [150, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [139, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19]]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 18, 13])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import remove_zero_rows\n",
    "generated = remove_zero_rows(generated)\n",
    "print(generated)\n",
    "print(generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens.shape: (234,)\n",
      "torch.Size([1, 18, 13])\n",
      "(18, 13)\n",
      "[['117',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0',\n",
      "  'molecule#edge#1',\n",
      "  'molecule#edge#2'],\n",
      " ['118',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['119',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['120',\n",
      "  'molecule#node#0#7',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['121',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['122',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['123',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['124',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['123',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['122',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['125',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['120',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['119',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['126',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['127',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['128',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['117',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "# File path to your vocabulary file\n",
    "vocab_file_path = \"/datalake/datastore1/yang/graph-gpt/data/OGB/pcqm4m-v2/vocab512_stacked\"\n",
    "\n",
    "from src.utils.my_utiles import load_vocab\n",
    "\n",
    "vocab = load_vocab(vocab_file_path)\n",
    "\n",
    "from src.utils.my_utiles import convert_labels_to_tokens\n",
    "# Example usage\n",
    "# Assuming `reshaped_labels` contains the predicted label IDs of shape [1, 24, 13]\n",
    "tokens = convert_labels_to_tokens(generated, vocab)\n",
    "print(\"tokens.shape:\", np.array(tokens).shape)\n",
    "# Optional: Reshape tokens back to the original structure for visualization\n",
    "# tokens_reshaped = [\n",
    "#     [tokens[i * 13 + j] for j in range(13)] for i in range(tensor_inputs[\"labels\"].shape[1])\n",
    "# ]\n",
    "tokens_reshaped = [\n",
    "    [tokens[i * 13 + j] for j in range(13)] for i in range(generated.shape[1])\n",
    "]\n",
    "print(generated.shape)\n",
    "# Print tokens\n",
    "print(np.array(tokens_reshaped).shape)\n",
    "pprint(tokens_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 13)\n",
      "(17, 13)\n",
      "[['117',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0',\n",
      "  'molecule#edge#1',\n",
      "  'molecule#edge#2'],\n",
      " ['118',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['119',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['120',\n",
      "  'molecule#node#0#7',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['121',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['122',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['123',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['124',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['123',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['122',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['125',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#2',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['120',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['119',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['126',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['127',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['128',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['117',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(tokens_reshaped).shape)\n",
    "tokens_reshaped = tokens_reshaped[:-1]\n",
    "print(np.array(tokens_reshaped).shape)\n",
    "pprint(tokens_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features: [[5 0 3 5 1 0 1 1 1]\n",
      " [6 0 2 5 0 0 1 1 1]\n",
      " [5 0 3 5 0 0 1 1 1]\n",
      " [7 0 3 5 0 0 2 0 1]\n",
      " [5 0 4 5 2 0 2 0 1]\n",
      " [5 0 4 5 1 0 2 0 1]\n",
      " [5 0 4 5 2 0 2 0 0]\n",
      " [6 0 2 5 2 0 1 0 0]\n",
      " [5 0 4 5 2 0 2 0 1]\n",
      " [5 0 2 5 0 0 1 1 1]\n",
      " [5 0 3 5 1 0 1 1 1]\n",
      " [5 0 3 5 1 0 1 1 1]]\n",
      "Edge Index: [[ 0  1  1  2  2  3  3  4  4  5  5  6  6  7  5  8  8  3  2  9  9 10 10 11\n",
      "  11  0]\n",
      " [ 1  0  2  1  3  2  4  3  5  4  6  5  7  6  8  5  3  8  9  2 10  9 11 10\n",
      "   0 11]]\n",
      "Edge Attributes: [[3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]\n",
      " [3 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import token_to_graph \n",
    "graph_x, graph_edge_index, graph_edge_attr = token_to_graph(tokens_reshaped)\n",
    "print(\"Node Features:\", graph_x)\n",
    "print(\"Edge Index:\", graph_edge_index)\n",
    "print(\"Edge Attributes:\", graph_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGbCAYAAABZBpPkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTAUlEQVR4nO3dd3gU1foH8O+2ZLNpmwYE0TRIIBBClS4CUgS8olJUkCLFi4oiivdeaV6ugh0LgkoVlS69CV5QInCRIkg1kAIEQggkm5Bt7M7O7w+S/RESYDfZ3Wz5fp6H52FnZ+Y9GTTzzpn3nCMRRVEEERER+SxpTTeAiIiIahaTASIiIh/HZICIiMjHMRkgIiLycUwGiIiIfByTASIiIh/HZICIiMjHMRkgIiLycUwGiIiIfByTASIXyc7OhkQiwUcffeT0WL/88gskEgl++eUXp8eytx3Dhw9HbGysy9tSU3GJPAGTAfI6WVlZePnll5GYmAiVSgWVSoXk5GS89NJL+PPPP2u6eVXyyiuvQCKR4OzZs3fcZ9KkSZBIJB77MzrCpUuX8Pbbb+PIkSM13RQijyKv6QYQOdKmTZswaNAgyOVyDB48GKmpqZBKpTh9+jTWrFmDuXPnIisrCzExMTXdVLsMHjwYX3zxBZYuXYqpU6dWus+yZcuQkpKCpk2bwmKxQK/Xw8/Pz8Utvbd58+bBYrE45dyXLl3Cv//9b8TGxqJZs2Yui0vk6ZgMkNfIyMjA008/jZiYGPz3v/9FdHR0ue/ff/99zJkzB1Lp3TvEtFotAgMDndlUu7Vp0wb169fHsmXLKk0G9u3bh6ysLLz33nsAAKlUCqVS6epm2kShUPhUXCJPwNcE5DU++OADaLVaLFq0qEIiAAByuRyvvPIK7r//fuu24cOHIygoCBkZGejduzeCg4MxePBgAEBaWhoGDBiABx54AP7+/rj//vvx2muvQa/Xlztv2TkyMzPRs2dPBAYGom7dupg+fTrutCjoN998g4SEBPj7+6N169Y4cODAPX++wYMH4/Tp0zh8+HCF75YuXQqJRIJnnnkGQOXv6s+cOYOnnnoKderUgVKpRL169fD000+jqKgIwP/XNCxevLjC+SUSCd5++23r53PnzuHFF19EUlISAgICEBERgQEDBiA7O/ueP8ft7+4ffvhhSCSSSv+UtaWgoABvvPEGUlJSEBQUhJCQEDz66KM4evSo9Ty//PILWrduDQAYMWJEhXNUVjOg1Wrx+uuv4/7774e/vz+SkpLw0UcfVfh3k0gkePnll7Fu3To0adIE/v7+aNy4MbZt23bPn5fIE7BngLzGpk2bUL9+fbRp08au48xmM3r27ImOHTvio48+gkqlAgCsWrUKOp0OY8eORUREBH7//Xd88cUXyMnJwapVq8qdQxAE9OrVC23btsUHH3yAbdu2Ydq0aTCbzZg+fXq5fZcuXYrr16/jhRdegEQiwQcffIAnn3wSmZmZd316HTx4MP79739j6dKlaNGiRbnYK1euRKdOnfDAAw9UeuyNGzfQs2dPGI1GjBs3DnXq1MHFixexadMmaDQahIaG2nXNDhw4gL179+Lpp59GvXr1kJ2djblz5+Lhhx/GyZMnrdfQFpMmTcKoUaPKbfv+++/x008/oVatWgCAzMxMrFu3DgMGDEBcXBzy8vLw9ddfo3Pnzjh58iTq1q2LRo0aYfr06Zg6dSrGjBmDTp06AQDat29faVxRFPG3v/0Nu3btwsiRI9GsWTP89NNPmDhxIi5evIhZs2aV2/+3337DmjVr8OKLLyI4OBiff/45nnrqKZw/fx4RERH2XD4i9yMSeYGioiIRgNivX78K3xUWFor5+fnWPzqdzvrdsGHDRADiP//5zwrH3bpfmZkzZ4oSiUQ8d+5chXOMGzfOus1isYh9+vQR/fz8xPz8fFEURTErK0sEIEZERIgFBQXWfdevXy8CEDdu3HjPn7N169ZivXr1REEQrNu2bdsmAhC//vpr67Zdu3aJAMRdu3aJoiiKf/zxhwhAXLVq1R3PXda+RYsWVfgOgDht2jTr58quzb59+0QA4pIlS+7YDlG8eb1iYmLu2I49e/aICoVCfP75563bDAZDuZ+5rL3+/v7i9OnTrdsOHDhwx5/h9rjr1q0TAYjvvPNOuf369+8vSiQS8ezZs9ZtAEQ/P79y244ePSoCEL/44os7/ixEnoKvCcgrFBcXAwCCgoIqfPfwww8jKirK+ufLL7+ssM/YsWMrbAsICLD+XavV4urVq2jfvj1EUcQff/xRYf+XX37Z+veybuUbN27g559/LrffoEGDEBYWZv1c9gSbmZl5rx8TQ4YMQU5ODnbv3m3dtnTpUvj5+WHAgAF3PK7syf+nn36CTqe7Z5x7ufXamEwmXLt2DfXr14dara70NYatLl++jP79+6NZs2aYM2eOdbu/v7+11kMQBFy7dg1BQUFISkqqcrwtW7ZAJpPhlVdeKbf99ddfhyiK2Lp1a7ntjzzyCBISEqyfmzZtipCQEJv+3YjcHZMB8grBwcEAgJKSkgrfff3119ixYwe+//77So+Vy+WoV69ehe3nz5/H8OHDER4ejqCgIERFRaFz584AYH3PXkYqlSI+Pr7ctsTERACo8B799q78ssSgsLDwTj+e1dNPPw2ZTIalS5cCAAwGA9auXYtHH320XIJxu7i4OEyYMAHz589HZGQkevbsiS+//LLCz2ErvV6PqVOnWt+1R0ZGIioqChqNpsrnNJvNGDhwIARBwJo1a+Dv72/9zmKxYNasWWjQoEG5eH/++WeV4507dw5169a1/rdTplGjRtbvb1XZK5iwsDCb/t2I3B2TAfIKoaGhiI6OxvHjxyt816ZNGzzyyCPo0KFDpcfe+tRZRhAEdO/eHZs3b8Y//vEPrFu3Djt27LAWo1VniJpMJqt0u3iHYsNb1apVC927d8ePP/4Ik8mEjRs34vr169aix7v5+OOP8eeff+Ktt96CXq/HK6+8gsaNGyMnJwfAzd6MygiCUGHbuHHj8O6772LgwIFYuXIltm/fjh07diAiIqLK12bixInYt28fVq5cWSE5mzFjBiZMmICHHnrIWk+wY8cONG7c2GXDBavz70bk7lhASF6jT58+mD9/Pn7//Xc8+OCD1TrXsWPHkJ6ejm+//RZDhw61bt+xY0el+1ssFmRmZlp7AwAgPT0dABw+693gwYOxbds2bN26FUuXLkVISAgee+wxm45NSUlBSkoKJk+ejL1796JDhw746quv8M4771h7FjQaTbljbn9CBoDVq1dj2LBh+Pjjj63bDAZDhWNttXz5cnz66af49NNPrb0vt8fr0qULFixYUG67RqNBZGSk9fOdEprKxMTE4Oeff8b169fL9Q6cPn3a+j2Rr2DPAHmNN998EyqVCs8//zzy8vIqfG/PE1zZU+Ctx4iiiM8+++yOx8yePbvcvrNnz4ZCoUC3bt1sjmuLfv36QaVSYc6cOdi6dSuefPLJe84pUFxcDLPZXG5bSkoKpFIpjEYjACAkJASRkZHl6hEAlHt3X0Ymk1W4nl988UWlvQj3cvz4cYwaNQpDhgzBq6++Wuk+lcVbtWoVLl68WG5b2fwQtiQlvXv3hiAI5f7dAGDWrFmQSCR49NFH7fgpiDwbewbIazRo0ABLly7FM888g6SkJOsMhKIoIisrC0uXLoVUKq20PuB2DRs2REJCAt544w1cvHgRISEh+PHHH+/4flipVGLbtm0YNmwY2rRpg61bt2Lz5s146623EBUV5dCfMygoCP369bPWDdjyimDnzp14+eWXMWDAACQmJsJsNuO7776DTCbDU089Zd1v1KhReO+99zBq1Ci0atUKu3fvtvZw3Kpv37747rvvEBoaiuTkZOzbtw8///xzlYbYjRgxAgCsrwBu1b59e8THx6Nv376YPn06RowYgfbt2+PYsWP44YcfKtRpJCQkQK1W46uvvkJwcDACAwPRpk0bxMXFVYj72GOPoUuXLpg0aRKys7ORmpqK7du3Y/369Rg/fny5YkEir1dDoxiInObs2bPi2LFjxfr164tKpVIMCAgQGzZsKP79738Xjxw5Um7fYcOGiYGBgZWe5+TJk+IjjzwiBgUFiZGRkeLo0aOtw8luHbpWdo6MjAyxR48eokqlEmvXri1Omzat3HC4sqF7H374YYVYuG3o3r1s3rxZBCBGR0dXGHInihWH9GVmZorPP/+8mJCQICqVSjE8PFzs0qWL+PPPP5c7TqfTiSNHjhRDQ0PF4OBgceDAgeKVK1cqtK+wsFAcMWKEGBkZKQYFBYk9e/YUT58+LcbExIjDhg27YzvKrtetQ/xiYmJEAJX+KbvOBoNBfP3118Xo6GgxICBA7NChg7hv3z6xc+fOYufOncv9DOvXrxeTk5NFuVxe7hyVDWm8fv26+Nprr4l169YVFQqF2KBBA/HDDz8ULRZLuf0AiC+99FKF63z7z0vkqSSiyOoXouoYPnw4Vq9eXelIBiIiT8CaASIiIh/HZICIiMjHMRkgIiLycawZICIi8nHsGSAiIvJxTAaIiIh8HJMBIiIiH8dkgIiIyMcxGSAiIvJxTAaIiIh8HJMBIiIiH8dkgIiIyMcxGSAiIvJxTAaIiIh8HJMBIiIiH8dkgIiIyMcxGSAiIvJxTAaIiIh8HJMBIiIiH8dkgIiIyMcxGSAiIvJxTAaIiIh8nLymG0BEROTOLKKIIqMZGoMJGoMJBkGAYBEhk0qglMmgViqgVioQ6i+HVCKp6eZWiUQURbGmG0FERORudCYzMjU6ZGl0MFlu3iolAG69ad76WSGVIE6tQrxaBZXCs561mQwQERHdwiRYcCy/GNlF+go3/3sp2z82NAApUSFQyDzjbTyTASIiolJ5WiMO5mpgFCzVPpdSJkXLaDVqB/o7oGXOxWSAiIgIQEahFkevFDv8vKm1QpAQFujw8zqSZ/RfEBEROZGzEgEAOHqlGBmFWqec21GYDBARkU/L0xqdlgiUOXqlGHlao1NjVAeTASIi8lkmwYKDuRqXxDqUq4HJAbUIzsBkgIiIfNax/GLccNEN2lA6SsEdedZASCIiIgfRmszILtLbdUzmiT+xYvbHOH34AG4YDah9fwy6DxiMPkNH2XR8dpEeDSOC3G4eAvdqDRERkYtkaXR2zSNw5LdfMHPscMQlN0H/seOhVAXi8oVsXMvLtTmmpDRu46iQqjTZaTi0kIiIfI5FFLH5bJ51ZsF70ZVcx7heHZHUvBXe+GwepNKqv2VXSCXoU7+2W01dzJoBIiLyOUVGs82JAACkbVoLzdV8PDv+n5BKpTDodLBYqlZrYLLcXOvAnTAZICIin6MxmOza/8+9aVAFBeNaXi7G9eqIwS3q47lWifj67X/ihtHg9PjOxmSAiIh8jsZggj2d9LnnsiAIZrz/0gg06/gwJn4+H12ffBrbly/B7H+9ZldsCdwvGWABIRER+RyDINi1AJFBp4VRr0ePp4di5OR3AABte/SG2WTC9hXf4elXJqJubLxN5xJL47sT9gwQEZHPEeyoFwAAP6USANCxT79y2zv2fQIAkH7kkFPjOxuTASIi8jkyqX2V/OFRtQEA6ojIcttDIyIAACXFRU6N72xMBoiIyOcoZTK7agbiGzcFABRcuVxue+GVPABAaFi4zeeSlMZ3J0wGiIjI56iVCrtqBto/+hgA4L+rl5Xb/vOqpZDJ5Wj8YHubzyWWxncnLCAkIiKfY+/NOD45BV2feho7f1wOQTCjcet2OP77PuzbthFPjhmH8Np1nBrf2TgDIRER+Rx7ZyAEALPJhDVff46da1agMD8PkXXr4dFnh6PvsNF2xXbHGQiZDBARkU86nl+MMwVau14XVJcEQGJ4oNutTcCaASIi8knxapVLEwHgZr1AnFrl4qj3xmSAiIh8kkohR2xogEtjxoYGuN3yxQCTASIi8mEpUSFQylxzK1TKpEhxs9cDZZgMEBGRz1LIpGgZrXZJrJbRaihclHjYyz1bRURE5CK1A/2RWsu5T+yptUJQO9DfqTGqg8kAERH5vISwQKclBKm1QpAQFuiUczsKhxYSERGVytMacShXA4Ngqfa5lKWvINy5R6AMkwEiIqJbmAQLjuUXI7tIDwlg1/DDsv1jQwOQEhXitjUCt2MyQEREVAmdyYwsjQ6ZGp11psLbk4NbPyukEsSrVYhTq9xy+ODdMBkgIiK6C4sooshohsZggsZggkEQIFhEyKQSKGUyqJUKqJUKhPrL3WqKYXswGSAiIqqEIAgwm83w8/ODxENv8rbyrH4MIiIiJxMEAXPmzMGuXbug0Wig0+kQExODLl26oHPnzmjYsKHXJQfsGSAiIrrF66+/jjVr1qBFixZITEyEXC7H5cuXcf78eVy8eBH9+/fHxIkTERjo3sMF7cFkgIiIqJTBYEBkZCRWrVqFRx991Lpdq9XiwoUL2L59OyZPnozZs2dj6NChNdhSx+JrAiIiolKnT59GYGAgOnbsWG57YGAgGjZsiIYNG0Kv1+OTTz7xqmTAMwZAEhERuUBISAji4uLw+uuvo7CwEBZLxcmHoqKioNfra6B1zsPXBERERLf44YcfMGPGDDRp0gQ9e/ZEamoqwsLCoNfrsXXrVvz444/o3Lkz3nvvvZpuqsMwGSAiIp9361wChfobyL54EecvXMS1/Cu4evkSzqWfgvZqHq7mnEef3r0xceJEREVF1XSzHYbJABER+SydyYxMjQ5Zd5llEBBvbpBIIBUtqB8RjHgPnGXwbpgMEBGRz/HF9QfuhskAERH5lDytEQdzNTD62MqEd8NkgIiIfEZGoRZHrxQ7/LyptUKQEOa5kxB5ft8GERGRDZyVCADA0SvFyCjUOuXcrsBkgIiIvF6e1ui0RKDM0SvFyNManRrDWZgMEBGRVzMJFhzM1bgk1qFcDUwOqEVwNSYDRETk1Y7lF+OGi27QhtJRCp7GewZJEhER3UZrMiO7yLapg4/v34tpw/pX+t3M5RuR2KylTefJLtKjYUSQR81D4DktJSIislOWRmf3PAK9nxuJ+inNym2rExNr8/GS0riNo0LsiFqzmAwQEZFXsogisjQ6uxIBAEhu2QbtevWtclwRQKZGh0aRwZBKJFU+jyuxZoCIiLxSkdFsnWLYXvqSEghmc5Vjmyw31zrwFOwZICIir6QxmKp03Oy3XoNBp4VUJkOjlm0wdOIU1E9JrVL8MKWiSm1wNSYDRETklTQGk131AnKFAm179EGLzl0REhaOC2fTsWHhV5gy5Am8u2w94pNTbI4tQdWTkZrA6YiJiMgr7btYgNyS6k0ClHsuCxMe74bkVm0xZf5Su46NDvJHu/vCqxXfVVgzQEREXkmoYr3AraJj4tC6a08c378XgiC4PL6rMBkgIiKvJJM6ppI/MrouzKYbMOp1NRLfFZgMEBGRV1LKZHDE7Tjvwnn4+SuhVNm+KqGkNL6nYDJAREReSa1U2DXHQFHBtQrbsk+fwMFd25Ha4SFIpbbfMsXS+J6CowmIiMgr2Xsz/uS1v8NPqURS81YIDY9ETkY6dqz8Hn7KAAx5fZLT49ckJgNEROSVQv3lUEglNk889GC3nkjbtBYbF30DvfY6QsIi0KZ7bwx8aQKiY+Lsiq2QShDq7zm3WA4tJCIir3U8vxhnCrR2T0lcHRIAieGBHrU2AWsGiIjIa8WrVS5NBICb9QJxapWLo1YPkwEiIvJaKoUcsaEBLo0ZGxrgUcsXA0wGiIjIy6VEhUApc83tTimTIsWDXg+UYTJAREReTSGTomW02iWxWkaroXBR4uFIntdiIiIiO9UO9EdqLec+safWCkHtQH+nxnAWJgNEROQTEsIC/z8hcPBAutRaIUgIs32GQnfDoYVERORTLpcYsONkJgKCQiCt5pTBytJXEJ7aI1CGPQNERORT0rZuxN+7tYVcWwgAdq9fULZ/bGgAusdFeXwiALBngIiIfEhJSQkaNWqEli1bYt26ddCZzMjS6JCp0VlnKpQA5eYmuPWzQipBvFqFOLXK44YP3o33/CRERET3cOjQIRgMBnz66acAbs5D0DgqBI0ig1FkNENjMEFjMMEgCBAsImRSCZQyGdRKBdRKBUL95ZBKPGdpYluxZ4CIiHyGIAjQ6/UICgqq6aa4FSYDRETkU0RRhMQLn+6rgwWERETkU5gIVMRkgIiIvIYgCAAAk8lUwy3xLEwGiIjIK/zwww8YMmQI6tSpg6eeegqzZs2CVqut6WZ5BCYDRETk8Y4dO4YXXngBtWvXxqRJkxAeHo5Nmzahbdu22LBhA1ged3csICQiIo83aNAgBAUFYcGCBdZte/bswdq1a5GWloZu3brh3//+NxQKRQ220n2xZ4CIiDya2WxGcHAw9Hp9ue0dOnTA5MmTMWDAAHzzzTdYuXJlDbXQ/TEZICIijyaXy9GhQwccOHAAv/76KywWi/U7tVqNN954A3379sWKFStqsJXujckAERF5vJ49e+K+++7DqFGjsHnzZty4caNcnUD79u1x6dIllJSU1GAr3ReTASIi8nh169bFzz//jAcffBBPPPEEhg0bhl27duGvv/7CqVOnMH/+fLRt25YzD94BCwiJiMirbN26Ff/6179w6dIlqNVqaLVapKSkYNu2bTXdNLfFZICIiLzSrl27YDAYEBERgQYNGiAsLKymm+S2mAwQERH5ONYMEBGRV7h1FAHZh8kAERF5vIyMDCxatIgzDVYRXxMQEZFbsYgiioxmaAwmaAwmGAQBgkWETCqBUiaDWqmAWqlAqL8cUokEoiiiT58+OHXqFE6dOgWlUlnTP4LHkdd0A4iIiABAZzIjU6NDlkYHk+Xmc6oEwK1PrBIAYtHNvyukEsSpVTiz/zds3boV69atYyJQRewZICKiGmUSLDiWX4zsIn2Fm78tLBYL0ven4Y0hA+AnlzmjiV6PyQAREdWYPK0RB3M1MArVLf4ToZTJ0DJajdqB/g5pmy9hMkBERDUio1CLo1eKHX7e1FohSAgLdPh5vRlHExARkcs5KxEAgKNXipFRqHXKub0VkwEiInKpPK3RaYlAmaNXipGnNTo1hjdhMkBERC5jEiw4mKtxSaxDuRqYql2L4BuYDBARkcscyy/GDRfdoA2loxTo3jjPABERuYTWZEZ2kd6mfY/v34tpw/pX+t3M5RuR2KylTefJLtKjYUQQVAre7u6GV4eIiFwiS6Ozex6B3s+NRP2UZuW21YmJtfl4SWncxlEhdkT1PUwGiIjI6SyiiCyNzu4JhZJbtkG7Xn2rHFcEkKnRoVFkMKQSSZXP4+1YM0BERE5XZDRbpxi2l76kBILZXOXYJsvNtQ7oztgzQERETqcxmKp03Oy3XoNBp4VUJkOjlm0wdOIU1E9JrVL8MKWiSm3wBUwGiIjI6TQGk131AnKFAm179EGLzl0REhaOC2fTsWHhV5gy5Am8u2w94pNTbI4tQdWTEV/B6YiJiMjp9l0sQG5J9SYByj2XhQmPd0Nyq7aYMn+pXcdGB/mj3X3h1YrvzVgzQERETidUsV7gVtExcWjdtSeO798LQRBcHt+bMRkgIiKnk0kdU8kfGV0XZtMNGPW6GonvrZgMEBGR0yllMjjidpx34Tz8/JVQqmxflVBSGp/ujMkAERE5nVqpsGuOgaKCaxW2ZZ8+gYO7tiO1w0OQSm2/fYml8enOOJqAiIiczt6b8Sev/R1+SiWSmrdCaHgkcjLSsWPl9/BTBmDI65OcHt/XMBkgIiKnC/WXQyGV2Dzx0IPdeiJt01psXPQN9NrrCAmLQJvuvTHwpQmIjomzK7ZCKkGoP293d8OhhURE5HRFRUVY8cs+hDVoApkL399LACSGB3JtgntgzQARETmNRqPB9OnTERsbi+njX7LrXb8jiADi1CqXxvRETAaIiMjhCgoKMHXqVMTExGDmzJkYNmwYft+T5vIbc2xoAJcvtgGvEBEROczVq1cxa9YsfPHFFzCbzRg7diwmTpyIOnXqAACiBAsulxhhECxOb4tSJkUKXw/YhDUDRERUbVeuXMHHH3+ML7/8EgDw0ksv4fXXX0etWrUq7JunNWJPToHT29ShXjhqB/o7PY43YDJAREQVlJSU4OTJk0hKSkJoaOgd9ysoKMCMGTMwd+5cSKVSjBs3DhMmTEBkZORdz59RqMXRK8WObrZVaq0QJITZPjGRr2PNABERWd24cQMTJkxAdHQ0hg8fjtTUVKxduxYWS8VufUEQcPLkScybNw+vv/46zp07hxkzZtwzEQCAhLBApNZyThc+EwH7sWaAiIisVq9ejV27dmHDhg2oU6cOPv30U0ycOBGCIKB///7l9pXJZOjYsSNycnIQHBxsd6yEsEAE+clxKFfjkBoCpUyKltFqvhqoAr4mICIiiKIIiUSCQYMGobCwENu3b7d+9/LLL+N///sffv31VwQGOv6J2yRYcCy/GNlFekgAu6YtLts/NjQAKVEhUMjY4V0VvGpERASJRAKj0QitVotmzZqV++6ZZ55BUFAQFi5c6JTYCpkULeqo0Ss+ConhgVDcssLg7Ysb3fpZIZUgMTwQveKj0KKOmolANfA1ARERAQD8/f1Rq1YtpKWloaioyFo42KZNG7Rv3x4rVqzAmDFj4O/vnG54lUKOxlEhaBQZjCKjGRqDCRqDCQZBgGARIZNKoJTJoFYqoFYqEOovh1TCpYkdgckAEZEbsIiiW9wAX331VTRv3hwHDhzAI488AlEUIZfL0bJlS6xduxYZGRlITk52WnwAkEokCFMqEMbFhVyGNQNERDVIZzIjU6NDlkZnXcTn9vfmt35WSCWIU6sQr1Y5bWa9Hj16wGKxYPny5daRARcvXsT999+PI0eOoGnTpk6JSzWHL1iIiGqASbDg8GUNtmXm40yBttxqfrc/od362WQRcaZAi22Z+Th8WQNTNavwK3se/PTTT7Fnzx7MnTsXV65cAQBs2bIFLVu2RERERLXikXtiMkBE5GJ5WiO2Z+Uju0gPwL7q+Vv3zy7SY0dWPvK0Rrvb8Oeff+KZZ55Bbm5uhTkEkpOT8e6772LFihXo2rUr+vfvj/Hjx+Nvf/sb7rvvPrtj2cJisUAQBKecm+6NrwmIiFzIWTPv2TrRzpEjRzB9+nSsXbsWsbGx+P7779G+fXtIbqtDEAQB6enp2LZtG7KzszFy5EinvB6wWCxYsmQJ0tLScOnSJRiNRiQnJ6NTp05o27YtYmJiHB6TKmIyQETkIjU5Be/Bgwfxn//8Bxs2bEBCQgImTZqEIUOGQKGovEivbN4BZ5s8eTLmz5+PJk2aIDk5GXK5HHl5ebh06RIKCwsxYsQIjB07Fn5+fk5viy/jaAIiIhfI0xqdmggAwNErxQjyk5ebgW///v2YPn06tmzZgsTERCxZsgTPPPMM5PK7//p3RSJw9epVfP7551i2bBn69OkD4GZPgUajwblz57B+/XpMnjwZsbGxePzxx53eHl/GZICIyMlMggUHczUuiXUoV4PucVE4sP9/mD59On766Sc0bNgQP/zwAwYNGgSZTOaSdtji5MmTCA0NRa9evazbpFIpwsPDER4ejubNm8NoNOKDDz5gMuBkLCAkInKyY/nFuOGAufdtYTALeG/xcnTo0AE5OTlYvnw5jh8/jmeffdatEgEAUKvViIyMxDvvvAOj0VjpyIbatWvDYDDUQOt8C3sGiIicSGsyW0cN3Mvx/XsxbVj/Sr+buXwjEpu1vPdJJBIkt++M1es34om+vSGVuu8zX9OmTfHss8/im2++wZUrV9CjRw8kJSUhODgYJSUl2LJlC5YvX46//e1vNd1Ur8dkgIjIibI0OrsX3+n93EjUT2lWbludmFibj5dKpUhs95BbJwJlXn31VYSGhmLOnDmYN28eAEClUiE6OhqCIOCJJ57Ayy+/XMOt9H5MBoiInMQiisjS6OyeRyC5ZRu069W3ynFFAJkaHRpFBrv93P1+fn4YM2YMxowZg5KSEqSnpyM3NxfXrl1D06ZNKyyaRM7BZICIyEmKjOZyMwvaQ19SAj+lErJ7VP3ficlyc60Dd5zf/67rMNRNQHJ8Q+s6DOQavNJERE6iMZiqdNzst16DQaeFVCZDo5ZtMHTiFNRPSa1SfHdKBmxeh6Ho5t9dsQ4D3cSrS0TkJBqDya56AblCgbY9+qBF564ICQvHhbPp2LDwK0wZ8gTeXbYe8ckpNseWoOrJiKOZBAuO5Rcju0hf4XrYsg5DeoEWsaEBSIkKgULm/nUQnogzEBIROcm+iwXILbF/3YBb5Z7LwoTHuyG5VVtMmb/UrmOjg/zR7r7wasWvrjytEQdzNTA6YGilUiZFy2h1uUmVyDGYYhEROYlQxXqBW0XHxKF11544vn+v3Qv5OCJ+dWQUarEnp8AhiQAAGAQL9uQUIKNQ65Dz0f9jMkBE5CQyqWMq+SOj68JsugGjXlcj8avCmeswHL1SzITAwZgMEBE5iVImgyNux3kXzsPPXwml6t6rEpaRlMavCa5ah6EqSzdT5ZgMEBE5iVqpsGuOgaKCaxW2ZZ8+gYO7tiO1g32TCIml8V3N1eswmFw0zbO342gCIiInsfdm/Mlrf4efUomk5q0QGh6JnIx07Fj5PfyUARjy+iSnx3cEl67DUDpKoUUdtUvieTMmA0REThLqL4dCKrF54qEHu/VE2qa12LjoG+i11xESFoE23Xtj4EsTEB0TZ1dshVTi8kl7XL4OA4DsIj0aRgRxHoJq4tUjInISqeTmpDlnCrQ2vS7oM3QU+gwdVe24EgDxapXLpyKuiXUYJKVxG0eF2BGVbsdkgIjIieLVKqQXuLbyXQQQp1a5NCbXYfBsLCAkInIilUKO2NAAl8aMDQ1webd5dddhEMzmKscuW4eBqo49A0RETpYSFYLLJUYYXFBYp5RJkVIDXeZch8GzMRkgInIyRek0untyCpweq2W0ukbm7+c6DJ6NaxMQEbmIM2flA4DUWiFICLN9YiJH4joMno01A0RELpIQFojUWs7pwq/JRADgOgyejskAEZELJYQFokO9cEgEk903vMooZVJ0qBdeo4kA4NvrMHgD1gwQEblYLZUfjMf3I0NrRqP2D9s9Nr9s/9jQAKREhdRIjcDtytZhqO7zuaetw+AtmAwQEbmYRCJB/yefAADcEG9OmpOp0VmH5t1+U731s0IqQbxahTi1yq1m3VMrFRCLbN+/qOAaQsMjym0rW4eheacuHrEOgzdxn/+SiIh8iFx+89evHEDjqBA0igxGkdEMjcEEjcEEgyBAsIiQSSVQymRQKxVQKxUI9Ze75eQ6vrgOgzfhaAIiIqoWi8WC/+7ciWuRsfALsK17f/OS+UjbtBa557Kt6zCktOtY5XUY+tSv7ZZJkqdgMkBE5ARmsxlyuRyCIEDmpe+zz58/j8WLF2PRokXIzs7GuHc+ROcnn4HEji7+6pIASAwP5NoE1VTzVSdERF5m2bJleO6555CcnIyhQ4di5cqVMFdjul13YjQasWrVKvTq1QuxsbH44IMP0LVrV+zZswczJ453aSIA1Mw6DN6IPQNERA7066+/4vHHH8ezzz6LiIgInDp1Crm5uTCbzZg1axbat29f002skmPHjmHBggX4/vvvce3aNbRv3x4jR47EwIEDERQUZN3v8GWNzcsYO0JsaABa1FG7LJ63YjJARORADz/8MFq3bo0PP/wQAKDT6bB7926sW7cOhw8fxsCBAzFhwgS7quVrSlFREZYtW4aFCxfiwIEDqFWrFoYOHYrnn38ejRo1qvQYk2DBjqx8l63D0D0uyi2GVno6jiYgInIQnU4HtVoNPz8/6zaVSoVevXohNTUVX375Jd577z00adIEvXr1qsGW3pkoiti9ezcWLFiA1atXw2g0onfv3li7di369OkDheLuVfu+sA6DN+JVJCJyEJVKhWbNmmHDhg34888/cWvHa3R0NN555x20adMGK1eudHpbLBYLTp48CYvFtif0ixcvYsaMGUhMTMTDDz+Mffv2YcqUKbhw4QI2btyIfv363TMRKFM70N9p0y6XSa0VgtqB/k6N4UuYDBAROdCgQYMgkUgwduxY/O9//6twM+7YsSMyMjJgMjlnlb38/Hw8//zzCA0NxVNPPYUePXrg9OnTle4riiLWr1+Pvn374oEHHsA777yD9u3b49dff0V6ejr+9a9/oW7dulVqhzevw+CNmAwQETlQo0aNsGXLFsjlcnTt2hWvvPIK9u7di4yMDJw8eRLfffcdunTpYvNTtr0WLFiA9PR0bN26FV9//TWKi4sxYsQIZGVlVdhXIpFg+fLlyM/Px5w5c5Cbm4tvv/0WDz30ECQOGLNftg6D0kFd+e6yDoM3YgEhEZGTLFmyBNOmTYPRaIRKpYLJZELTpk2xceNGp8S7fv06unbtinbt2uHzzz8HcHMugFGjRiEhIQFz584tt7/FYoFOpys3GsAZTIIFx/KLkV2k94p1GLwRCwiJiJxk6NChGDp0KDZv3gyLxYLatWsjKSnJafGKiopQUlKCBx980LrtgQceQO/evTFv3jwUFhYiLCzM+p1UKnV6IgDcLCpsUUeNhhFBXrEOgzfi1SUicrI+ffq4JE69evWg1+tx5swZiKJo7erv2LEj1q1bhy1btmDw4MEuaUtlVAq5V6zD4I34moCI6C4somj3jctisdTYPAKvvfYadu7cid9++w3BwcEAgJKSEowaNQoqlQoLFixwSD0AeRf2DBARVUJnMiNTo0PWvbq0S5ftVUgliFOrICu6im0b1+PVV1+tkYTg+eefx2effYa0tDQ8+uijkEgkCAoKgsVigVarZSJAlWIlBhHRLUyCBYcva7AtMx9nCrTWRACoWPh262eTRcSZAi1OmvxxCUqU6A1Oa6NWq8WaNWsq/S4lJQWPPPIIPvvsM5w4cQIAYDAYkJOTA7Va7bQ2kWfjawIiolJ5WiMO5mpgrOZUuqIoIkAuQ8totcMmxhFFEQcOHMCCBQuwbNkyXL9+HceOHUNycnKFHohDhw7hH//4B06fPo233noLO3fuxIkTJ7B+/XokJiY6pD3kXZgMEBEByCjU4uiVYoeft7oT5Fy9ehXfffcdFixYgBMnTqBevXoYMWIERowYgbi4uDsed/78ecybNw+//fYboqOj8a9//QspKSlVbgd5NyYDROTznJUIlLE3IRAEATt27MCCBQuwfv16AEC/fv0wcuRIPPLII5DJZHc9/taRBES2YDJARD4tT2t0yaI6HeqF3/OVQWZmJhYtWoTFixcjJycHTZo0wciRIzFkyBBERkY6vY3ku5gMEJHPMgkWbM/Kr3aNgC3utNyuXq/HmjVrsHDhQuzcuRMhISF45pln8Pzzz6N169Z8wieX4NBCIvJZx/KLccMFiQAAGEqn5G1RRw0AOHz4MBYsWIClS5dCo9HgoYcewrfffov+/ftDpVK5pE1EZdgzQEQ+SWsy46fMfJv2/eKf4/HLujsvO/zNr4cQUTvapnPlpW3FN19+gSNHjiA6OhrDhw/HiBEj0KBBA5uOJ3IG9gwQkU/K0uhsXjSnx6AhaNq+U7ltoijim7f/gaj77rc5ERAEM/acOovY2Fj85z//Qa9evSCX89cw1Tz+V0hEPsciisjS6GxePS+peSskNW9VbtupQ/th1OvxUN8nbY4rk8kx8IVx6NugDufcJ7fCGQiJyOcUGc3lZhasirRN6yCRSNCp7xN2HWcWb8YncidMBojI52gMpmodbzaZsHfrBiQ1b4Va9e53eXwiR2MyQEQ+R2MwoTqd9Ed++wXXNYXo9JjtrwjKSMBkgNwPkwEi8jkGQbC5XqAyaZvWQq5QoEOvx+w+ViyNT+ROmAwQkc8RqlEvoNdqcWDnT0jt0BnBYeEuj0/kDEwGiMjnyKRVf0nw+3+33RxFUIVXBI6IT+QMTAaIyOcoZbIq1wykbVwDpSoQrbv2qNLxktL4RO6EyQAR+Ry1UlGlmoGigmv4c18a2nR/FP4BVZsyWCyNT+ROmAwQkc+p6s14z5b1EMxmdLJjoiFHxidyFiYDRORzQv3lUFThvX3axrUIjYisMDWxPRRSCUL9OfkruRcuVEREPul4fjHOFGirNcTQXhIAieGBaBwV4sKoRPfGngEi8km6nCxYXPwsJAKIU3N5YnI/TAaIyKdcvnwZI0eORNuWzXHo5y2ACxOC2NAAqBR8RUDuh8kAEfkEg8GAmTNnokGDBli/fj1mz56NKWOGQil3zTA/pUyKFL4eIDfFZICIvJooili9ejUaNWqEqVOnYtSoUThz5gxefPFFBPj5oWW02iXtaBmthkLGX7nknvhfJhF5rcOHD6Nz584YMGAAmjRpguPHj2PWrFkICwuz7lM70B+ptZz7xJ5aKwS1A/2dGoOoOpgMEJHXyc3NxfPPP49WrVqhoKAAP/30EzZu3IikpKRK908IC3RaQpBaKwQJYYFOOTeRo7CShYi8hsFgwKxZszBjxgz4+/tj9uzZGDNmDOTye/+qSwgLRJCfHIdyNTAIlmq3RSmTomW0mj0C5BE4zwARebyyuoA333wTOTk5ePnllzF16tRyrwNsZRIsOJZfjOwiPSSAXfMQlO0fGxqAlKgQ1giQx2AyQEQe7fDhwxg/fjzS0tLQt29ffPTRR3d8HWAPncmMLI0OmRodTKVLDt+eHNz6WSGVIF6tQpxaxeGD5HGYDBCRR8rNzcWkSZOwePFiJCcn45NPPkGPHlVbSfBuLKKIIqMZGoMJGoMJBkGAYBEhk0qglMmgViqgVioQ6i+HVMKlickzMRkgIo9ye13A9OnTba4LIKLK8f8eIvIIjqwLIKLymAwQkdu7vS5g27ZtDqkLIKKbWOpKRG5Lp9PZNV8AEVUNkwEiqhH79u1Dbm7uXfdRqVQ4d+4cvvzySxw5csQpBYJExAJCInKxtLQ0jBw5Enq9HlKpFJ06dcIHH3yAunXrVthXEARYLBYoFIoaaCmR72AyQEQuc/nyZQwaNAht27bFCy+8gBMnTmDChAlo3Lgxli9fDqVSWdNNJPJJfE1ARC5z9uxZ/P7773juuecQHx+Pxx57DJ988gmKi4vx4Ycf1nTziHwWkwEicplr165VKP7r27cvevXqheXLl9+zhoCInIPJABG5TJMmTfDXX3/h5MmT1m0SiQS9e/dGbGws5syZU4OtI/JdTAaIyGUSEhLQu3dvzJo1C0VFRdbtTZo0QXR0NA4fPgyLpforBhKRfZgMEJFLvfvuuzh06BC+/fZbGI1G6/bY2FicOHGiBltG5Ls4AyEROY3ZbIZUKoVU+v/PHQ0bNsTkyZMxY8YMBAQE4NlnnwUA7N+/H88++2y5fYnINTi0kIgcrmwdgWnTpuGXX35BZGRkhZv8uHHjsHbtWtx33324evUq5HI5Vq5cidTU1BpqNZHvYjJARA516NAhjB8/Hr/99hsee+wxfPPNN6hTp06F/YxGI06dOoVDhw5BJpNh+PDhrm8sEQFgMkBEDpKbm4tJkyZh8eLFSE5OxqxZs9C9e/eabhYR2YA1A0RULXq9HrNmzcKMGTOgVCrx5ZdfYvTo0ZDL+euFyFPw/1YiqhJRFLFq1Sq8+eabuHjxIl555RVMmTIFarW6pptGRHZiMkBEdru9LmD79u1ITEys6WYRURUxGSDyUBZRRJHRDI3BBI3BBIMgQLCIkEklUMpkUCsVUCsVCPWXQyqROCTmpUuXMGnSJHz77bdITk7G9u3bWRdA5AWYDBB5GJ3JjEyNDlkaHUyWm/W/EgC3VgJLAIilE/wppBLEqVWIV6ugUlTtf3nWBRB5N44mIPIQJsGCY/nFyC7SV7j530vZ/rGhAUiJCoFCZtvEPqwLIPINTOuJPECe1oiDuRoYhZvz9tubwZftn12kx+USI1pGq1E70P+ux7AugMh3cN5PIjeXUajFnpwCayJQXQbBgj05Bcgo1Fb6/aVLlzBixAi0bt0ahYWF2L59OzZs2MBEgMiLsWeAyI1lFGpx9EqxU85ddt6EsEAA5esCAgICMGfOHIwaNYp1AUQ+gP+XE7mpPK3RaYlAmaNXihGokGH3lg2sCyDyYUwGiNyQSbDgYK7G+YFEEdtPZODvz49E925dWRdA5KM4moDIDR2+rMG5Ir3dhYJVYREE+OmL8LeWjV0QjYjcEXsGiNyM1mRGdpHepn2P79+LacP6V/rdzOUbkdis5T3PIZXJYA4Kh85krvI8BETk2fh/PpGbydLo7J5HoPdzI1E/pVm5bXViYm0+XlIat3FUiB1RichbMBkgciMWUUSWRmf364Hklm3QrlffKscVAWRqdGgUGeywqYuJyHNwngEiN1JkNFunGLaXvqQEgtlc5dgmy821DojI97BngMiNaAymKh03+63XYNBpIZXJ0KhlGwydOAX1U1KrFD9MqahSG4jIczEZIHIjGoPJrnoBuUKBtj36oEXnrggJC8eFs+nYsPArTBnyBN5dth7xySk2x5ag6skIEXk2Di0kciP7LhYgt8RYrXPknsvChMe7IblVW0yZv9SuY6OD/NHuvvBqxSciz8OaASI3IlSxXuBW0TFxaN21J47v3wtBEFwen4g8D18T+DCLeLNgTGMwQWMwwSAIECwiZFIJlDIZ1EoF1EoFQv3lrDB3Ep1OhzNnzuCvv/7CX3/9hbDUdohOTIakmtc7MrouzKYbMOp1UAUF23ycTMp/ZyJfxGTAB+lMZmRqdMjS6KyV67e/p5YAEItu/l0hlSBOrUK8WsVJaarAYrHgwoUL1hv+rX8uXLhg3S8yMhIvvvMA6tRvCIlMVq2YeRfOw89fCaUq0OZjJACU1YxLRJ6Jv9l9iEmw4Fh+MbKL9BVu/rd3Dt/62WQRcaZAi/QCLWJDA5ASFQKFzDPeMBmNRpw6dQp//PEHcnNz0alTJ3To0AFSqePbX1RUhL/++gvp6enlbvhnzpyBXn9zRkE/Pz80aNAAiYmJGDx4MJKSkqx/wsPDkaXR4Y+8IttjFlxDaHhEuW3Zp0/g4K7taN6pi10/pwhAzZEERD6JBYQ+Ik9rxMFcDYyCpdrnUsqkaBmtRu1Afwe0zHkuXLiAV155BYcOHULdunURGhqKCxcuYNCgQZg2bVqVzmk2m5GVlVXpU35eXp51v7p165a70Zf9iYmJgewuT9+FBhN2nbtqc3umDRsAP6USSc1bITQ8EjkZ6dix8nvI5ArMXL4R9RIa2PXzdYmJ5NBCIh/EZMAHZBRqnbIUbmqtECSE2d4N7WoajQa7du1CixYtEBMTAwCYPn06lixZgvXr16Nx48oX5hFFEVevXq1ws09PT0dGRgZMppvD71QqlfUmn5iYWO7vwcG2v6e/lUUUsflsns0TD21eMh9pm9Yi91w29NrrCAmLQEq7jhj40gREx8TZFVshlaBP/dqsDyHyQUwGvJyzEoEy7p4Q3G7p0qUYM2YMcnJyoFarK90nOTkZp06dAgBIJBLExMRU+pR/3333VbvQrzLH84txpkDrkhULy0gAJIYHcm0CIh/FmgEvlqc1OjURAICjV4oR5Cd361cGOp0OmzZtwqFDh5CWloYlS5bcMREAgEmTJsHf3x9JSUmoX78+AgICXNdYAPFqFdILtC6NKQKIU6tcGpOI3Ad7BryUSbBge1a+Q2oE7kUpk6J7XFSNFhXq9fo73rT/+usvDBw4EOHh4bhx4wbMZjPmz5+PlBTbZ+dztcOXNTYvY+wIsaEBaFFH7bJ4RORemAx4qcOXNThXpHdZV7MrbiaCIOD8+fOVFu/5+fkhMzPznucoLCzEc889B4VCgS+++AL16tVzapuryiRYsCMrHwYfSeaIqGbxNYEX0prMdj9VZp74Eytmf4zThw/ghtGA2vfHoPuAwegzdJRNx2cX6dEwIsgh8xAUFhZWesM/e/YsjMabU/X6+/ujQYMGSEpKwrBhw9CwYUNYLJa7DqUzm80ICwvD448/jq+//hqXL19222RAUTpiY09OgdNjtYxWMxEg8nFMBrxQlkZn12I3R377BTPHDkdcchP0HzseSlUgLl/IxrW8XJtjSkrj2lqAZjKZkJGRUWFM/l9//YX8/HzrfvXq1UNSUhI6d+6MMWPGWIv37r///rsO0bs9lkKhgFwuR2FhIZYtWwZ/f38kJiba/PPVhNqB/kitFeL0AlB3rvcgItfgawIvY+/QNF3JdYzr1RFJzVvhjc/mVWsyntuHpomiiCtXrlT6lJ+ZmWmdNz8oKKjc0Lxbh+gFBlZvpMLVq1cxc+ZMNGzYEGfOnMHRo0cBANOmTUP79u2rdW5X8dWhoUTkOuwZ8DJFRrPNiQAApG1aC83VfDw7/p+QSqUw6HTwUyqrlBSYLCI++fIr/Pn7PutNv6jo5mx6UqkUsbGxSEpKQp8+fcrd9KOjo50yRA8AQkJCkJOTg3379qFWrVro3r07evXqhSZNmjglnjMkhAUiyE+OQ7kah9QQeMqkUUTkOkwGvIy969H/uTcNqqBgXMvLxfsvjcCl7EwoVSo89Lf+GPGvt+Hnr7T5XKIo4rdDf+DK2bNo1KgR+vXrZ73h169fH/7+rr/5+Pn5YcWKFS6P62i1A/3RPS4Kx/KLkVWohSiKkNqxjkDZayNPm06aiFyDrwm8zB+Xi5BdpLO5XmDC44/g8vksAEC3p55B4wfb48Tve7Hl+4Xo0PtxTPhkrs2xJQBiQ1VoXifU/oaTTXJyctCyXXt8NP87qOOT7r7QVOnfFVIJ4tUqxHGhKSK6A/5m8DIGQbBrOKFBp4VRr0ePp4di5OR3AABte/SG2WTC9hXf4elXJqJubLxN5xJL45Pz1K5dGzPenoYnO7ZCgErFJaiJyCGYDHgZwY56AQDwU958DdCxT79y2zv2fQLbV3yH9COHbE4GqhKf7KNQKDB8+HDrSIowpYILCxFRtfHFoZeRSe17AgyPqg0AUEdEltseGnFzWdySYtuX061KfLKfrUMqiYhsxWTAyyhlMthzO45v3BQAUHDlcrnthVduLscbGhZu87kkpfGJiMizMBnwMmqlwq6agfaPPgYA+O/qZeW2/7xqKWRyORo/aPtYfLE0PhEReRbWDHiZEIV9+V18cgq6PvU0dv64HIJgRuPW7XD8933Yt20jnhwzDuG169h1PiYDRESeh0MLvUROTg4WLlyIRYsX4+1lmxCsDrP5WLPJhDVff46da1agMD8PkXXr4dFnh6PvsNF2teH2GQipavLy8nDq1CkoFAq0b9/eaRMyERGVYTLgwcxmM7Zs2YJ58+Zhy5YtCAgIwDPPPIOBL7+BEmWIy1YsBG7WCySGB9q8NgFVbuvWrfj888/x008/ITIyEjNnzsTIkSMBAAUFBQgPt72Gg4jIVkwGPFB2djYWLFiAhQsX4tKlS2jVqhVGjx6NZ555BsHBwdCZzNiWmX/vEzlYr/goTmpTTU2aNEHPnj0xYcIELFq0CCdPnkSHDh2wefNmiKKIJ598EiNHjqzWGhJERLdjMuAhTCYTNmzYgHnz5mH79u0ICgrCkCFDMHr0aDRv3rzC/ocva+xexrg6YkMD0KKO2mXxvNHu3bsxcOBAnD17FkFBQSgpKUF0dDTatWuHxo0b48qVK/jll1+wbNkyPPTQQzXdXCLyInyMc3Nnz57F/PnzsXjxYuTl5aFt27ZYsGABBg4ceNcV/VKiQnC5xOiQhW3uRSmTIoWvB6ptxYoV6NWrF1QqFQBg/fr1UKlU+PrrrxEXF4cbN26gU6dOOHjwIJMBInIoJgMuJAiCTRPGGI1GrF27FvPmzcPOnTuhVqvx3HPPYfTo0UhJSbEplqJ0Zbo9OQXVbfY9tYxWc+GbarJYLEhISEBkZCTKOuuOHDmCl156CXFxcTCbzfDz80Pbtm1x4sSJGm4tEXkbviZwgZ07d2Lu3Lkwm81o3bo1XnzxRajV6gr7iaKI4uJiNGjQAPn5+ejUqRNGjx6N/v37IyAgoEqxMwq1OHqluJo/wZ2l1gpBQtideyjIdmX//qGhNxd60uv1kMvlUCgU1u+Tk5MxefJkDB48uCabSkRehj0DTvT777/jH//4B/766y88+eSTqFu3LmbMmIGsrCy89957iCid8reMRCJBaGgo3n33XXTs2BGNGjWqdhvKbtTOSAiYCDhW2b9/mYCAAGsvgdlsxoYNG3D16lUmAkTkcEwGnMhoNKJ79+5YtGgRYmNjAQARERGYOnUqPvvss0qPEUURo0fbN77/XhLCAhHkJ8ehXI1DagiUpa8gagf6O6B1dDdlcwxs374dn376KV577bUabhEReSO+JnCiGzduoKSkpNzY8Pfeew+XL1/Gxx9/7PIFZ0yCBcfyi5FdpC+33r0tyvaPDQ1ASlQIawRqwJUrVxAUFGQtMCQichSPTwYsougRa7qvWbMGU6dOxcmTJ9G7d2907twZY8eORVBQkMvbojOZkaXRIVOjg6l0yeHbk4NbPyukEsSrVYhTqziPgAuIoghBECCX81oTkWt4bDKgM5mRqdEhy44bWpxahfgauKFZLBZ89NFHuHbtGvr27Yv9+/djwYIF6NatG2bPnu3StpRrl4ckUr5mwYIFuHjxIiZNmsTlionIJTwuGXDnru6yS2nLXPKTJk3Cnj17sGTJEjzwwAMObQe5J1uSr1B/OTq1boEmjRtjxYoVNd1kIvIRHtUPmac14mCuBsbSIjh7s5iy/bOL9LhcYnRYEZxGo8EPP/yAffv24fvvv68YVxStCYLZbIZcLseFCxdw9epVREZGVjs+uTebe7GKbv79zQUrESW3QGcy87UMEbmEx1SBZRRqsSenwJoIVJdBsGBPTgEyCrVVOl4URezduxfDhw9H3bp18eqrr0Kr1eL69eu4vbNFIpFAEAQAgFQqxapVq5CVlYUpU6awGMyLmQQLDl/WYFtmPs4UaK2JAFAxkb31c7A6DMagCGzLzMfhyxqYXDCLJBH5No94TeBOE+cUFBTgu+++wzfffIOTJ08iNjYWo0ePtiYFd/Kf//wH+fn52Lx5M3Q6HV555RWMHz++ypMJkXu7vRerOjiUk4icze2TgTyt0SVT6naoF37HX7aiKGL37t2YN28eVq9eDUEQ0K9fP4wZMwbdunWzaQW5/fv3Y968eejevTsGDRrk6OaTG3FW8spJnojIWdw6GTAJFmzPynfYq4G7Ucqk6B4XVa6oMD8/H99++y3mzZuH9PR01K9fH2PGjMGwYcNQq1Ytp7eJPI879WIREdnKrauTjuUX44aL3pcaSkcpNKsVgp07d2LevHlYu3YtJBIJnnrqKXz99dfo3LmzTSMFyDflaY1OTQSAm9NKB/nJ+cqAiBzKbXsGtCYzfsrMt2nf4/v3Ytqw/pV+N3P5RiQ2a2nTeURRxIwR/XH4f/vQqFEjjB49Gs899xwr/umearoXi4ioOty2ZyBLo7N7HoHez41E/ZRm5bbViYm1+XiLRcCA0S/hsw8/QIcOHdgLQDariV6sFnXULolHRN7PLZMBiygiS6Ozex6B5JZt0K5X3yrHlcnkaNypG9rXr81EgGymNZmRXaS3aV9H9WJlF+nRMCKI8xAQkUO45W+SIqO53Jhse+hLSuCnVEJWxXndTZabs8SFKRVVOp58T030YklK4zaOCrEjKhFR5dwyGdAYTFU6bvZbr8Gg00Iqk6FRyzYYOnEK6qekVik+kwGyRU31YokAMjU6NIoM5roRRFRtbpsM2POkJVco0LZHH7To3BUhYeG4cDYdGxZ+hSlDnsC7y9YjPjnF5tgSVD0ZId/DXiwi8gZuOZpg38UC5JYYq3WO3HNZmPB4NyS3aosp85fadWx0kD/a3RderfjkG7I0OvyRV2Tz/mU1A0pVoEN6sZrXDkWcmlNaE1H1uGXPgFDFJ61bRcfEoXXXnti/YysEQbBrKVhHxCffwF4sIvIGbpkMyKSOeQcaGV0XZtMNGPU6qIKCXR6fvJ9BEOyqF2jYojUatmht/dy6a0+069kXEx7vhh8+mWlXL5ZYGp+IqLrcctYSpUwGR9yO8y6ch5+/EkqV7dO3SkrjE9nCkb1Yx/fvta5u6cr4RERumQyolQq7nraKCq5V2JZ9+gQO7tqO1A4P2bSQUBmxND6RLZzRi1UT8YnIt7nlawJ7b8afvPZ3+CmVSGreCqHhkcjJSMeOld/DTxmAIa9Pcnp88l1lvVjVfT5nLxYR1SS3TAZC/eVQSCU2D9l6sFtPpG1ai42LvoFeex0hYRFo0703Br40AdExcXbFVkglCPV3y8tCbkitVEC0fTABigquITQ8oty2sl6s5p26sBeLiGqEWw4tBIDj+cU4U6Ct9hOXPSQAEsMDOasb2azQYMKuc1dt3n/asAGV9mLJ5ArMXL4R9RIa2BW/S0wk5xkgompz20fgeLUK6QVal8YUAY7ZJruwF4uIvIHb9gwAwOHLGpsXgHGE2NAArgRHdtuflYscgwUSO7r4q4u9WETkSG45mqBMSlQIlC5as10pkyKFv1jJDtevX8e0adMwoPtDLo/NXiwiciS3TgYUMilaRqtdEqtltBoKFyUe5NlMJhPmzJmD+vXr4/3338ez/Z9CXZVr39vHhgZw+WIichi3v/vVDvRHai3nPrGn1gpB7UB/p8YgzyeKIn788Uc0btwYL7/8Mh599FGkp6fjvffeQ6t6kezFIiKP5fbJAAAkhAU6LSFIrRWChDDbx3aTb/rtt9/Qvn179O/fHwkJCThy5AgWL16MBx54AAB7sYjIs3nMb5SEsEB0qBfusKcvpUyKDvXCmQjQXZ0+fRr9+vVDp06dcOPGDfz888/YunUrmjZtWmFf9mIRkafymGQAuPnLtntcFGJDAwDA7vULyvaPDQ1A97go/lKlO8rNzcULL7yAJk2a4OjRo/jhhx9w4MABdOvW7a7HsReLiDyRWw8tvBudyYwsjQ6ZGp11jPft08Le+lkhlSBerUKcWmUtvCosLERhYSHi4+Nd2XSqQSaTCQrFnYv9RFHEiRMn0KZNGyiVSkyePBkvvvgi/P3tSxzztEYcytXAIFiq22QoS19BMHklImfx2GSgjEUUUWQ0Q2MwQWMwwSAIECwiZFIJlDIZ1EoF1EoFQv3lkEr+vy9BEAT88MMP+PHHH7F+/foa/AnIFQ4dOoT3338farUasbGxePXVVxEYeOen7NmzZ2PIkCFQq9VVjmkSLDiWX4zsIr3d6xeU7R8bGoCUqBDWCBCRU3l8MnA3V65cQXp6Ojp27GjdZjQaIZfLIZPJkJmZiYcffhgrVqxAu3btarCl5CyFhYV49dVXsX79egwYMABqtRqffvopJk+ejEmTJlXaSyCKIiQSx60G6IheLCIiZ/Lq3zTjxo1DTEwM2rRpY/2l/+abb6JNmzZ49tlnER8fj9atW2PdunVMBryQKIqYP38+DAYD0tLSrEV/JpMJ69atw9tvv13pcY5MBABApZCjcVQIGkUGV6kXi4jI2bw6GQgODoZGo4FCobA+7Wm1Wvzwww949tlnAQAxMTHIyMio4ZaSM0gkEvTv3x+PPvooGjdubN0uk8kwcuRI6HQ6qFSum8VPKpEgTKngwkJE5Ha8+kXkI488gr1790IQBOvTXnx8PNLS0rB582Zs374dP/74I/r27VvDLSVniYuLQ5MmTSCRSHDixAm0atUKn376KZYsWYKOHTti9erVNd1EIqIa59XJQJ8+fWA0GrFo0SJYLBacOXMGK1euxJQpU/DSSy/h6aefRvPmzdG7d++abio5mSiK2Lt3r3Wo4OLFi5Gamor3338fu3fvrunmERHVKK8uIASA+fPnY/LkyYiIiEBoaCiCg4Px/fffQyqVIicnBw888ADCwsJqupnkAhaLBVKp1PrK6Pjx4+jZsycWLVqEHj161HTziIhqjFfXDADAqFGjEBcXhz1798Is90ePvz2BHMEPhhsChPB6OK0ToTQWsXjLCao67LO67jQaQHrbEsPnz5+HIAiIiopyWGwiIk/k9T0DOpMZmRodsuwY1hWnViGew7qqrCaveVpaGk6cOIExY8ZUuPkDwI0bN+Dn54dff/0Vb731Flq1aoWPP/4Ycjn/rYnId3ltMsAJX1yvJq/5qVOn8M9//hMbNmxA+/btsWvXLvj5+ZXbR6vVYsqUKcjIyMCOHTswfvx4vPvuuw4fSkhE5Gm88nEoT2vEwVwNjKVTwdqb7ZTtn12kx+USI6eCtUFNXfNLly7h7bffxoIFCxATE4OlS5di0KBBlfYKBAYGIikpCSqVCgsXLkRERISdrSQi8k5e1zOQUajF0SvFDj8vF4m5s5q45sXFxfjwww/xySefQKlUYsqUKRg7duw91xBw9OyCRETewKt6Bpx1UwJgPS8TgvJcfc1NJhO++eYb/Pvf/8b169cxfvx4/OMf/7B5DQEmAkREFXnNy/A8rdFpN6UyR68UI09rdGoMT+LKay6KIlavXo3k5GSMGzcOffv2RXp6OmbOnFmtxYSIiMhLkgGTYMHBXI1LYh3K1cDkgGVpPZ0rr/m+c1fQuUtXDBgwAImJiTh69CgWLlyI+++/3yXxiYi8nVfUDBy+rMG5Ir3dRWtVFRsagBZ11C6K5p5cec0FQcCfv+5Al6QYdO3a1QURiYh8i8cnA1qTGT9l5tu07/H9ezFtWP9Kv5u5fCMSm7W0OW6v+CifnYeA15yIyLt4/G/WLI3O7jHtvZ8bifopzcptqxMTa/PxktK4jaNC7IjqPXjNiYi8i0cnAxZRRJZGZ3dXdXLLNmjXq+orFYoAMjU6NIoMdtnUxXPnzsXcuXNx7tw5AECTJk0wdepU9OzZ0yXxy/jSNSci8hUeXUBYZDRbp7u1l76kBILZXOXYJsvNefdd5f7778cHH3yAP/74A4cOHUKXLl3w+OOP4/Tp0y5rA+Bb15yIyFd4dM+AxmCq0nGz33oNBp0WUpkMjVq2wdCJU1A/JbVK8cOUiiq1wV59+5Z/qn7nnXcwd+5c7N+/Hw0bNnRJGwDfuuZERL7C45MBe95dyxUKtO3RBy06d0VIWDgunE3HhoVfYcqQJ/DusvWIT06xObYEVb8xVpcgCFixYgX0ej3atWvn0ti+es2JiLyZR48m2HexALkl1ZsEKPdcFiY83g3JrdpiyvylNh8niiLOHv4daz6bWel3d/t8t33effdddO/eHTKZrMIxx44dQ7t27WA0GhEcHIxly5bdsWYgKysL/fr1syu2Le0d/K/paNi6fbVm8qvqNQeA6CB/tLsvvMqxiYioIo/uGRCq+O76VtExcWjdtSf279gKQRAqvQlXRiKRQB0ejqZNm1o/V7bP3T5Xti0iIuKON9qGDRvizz//RHFxMVatWoXnnnsOu3fvrvQ1QUBAADp37nzPePa2s0503WpP6VvVaw445t+ciIjK8+hkQCZ1TFV5ZHRdmE03YNTroAoKtvm4pilN8EKveQ5pgy0UCgXi4+MBAM2aNcPvv/+Ozz77DHPnzq2wb506dfD55587vA2O6I0Bqn7NHfVvTkRE/8+jRxMoZTI44taQd+E8/PyVUKpsX4RIUhq/JgmCgBs3brg0pq9fcyIib+TRyYBaqbBrvHtRwbUK27JPn8DBXduR2uEhSKW2Xw6xNL6rvPXWW0hLS8O5c+dw7Ngx/POf/8Tu3bsxZMgQl7UB8K1rTkTkKzz6NYG9N4ZPXvs7/JRKJDVvhdDwSORkpGPHyu/hpwzAkNcnOT1+dVy5cgXDhg1Dbm4uQkNDkZqaiu3bt6NLly4uawPgW9eciMhXePRoAosoYvPZPJsnwdm8ZD7SNq1F7rls6LXXERIWgZR2HTHwpQmIjomzK7ZCKkGf+rV9bjY8XnMiIu/j0ckAABzPL8aZAq3LViwEbr67TgwP9Nl58nnNiYi8i0fXDABAvFrl0psScPPddZxa5eKo7oPXnIjIu3h8MqBSyBEbGuDSmLGhAT69lC6vORGRd/H4ZAAAUqJCoJS55kdRyqRIYVc1rzkRkRfximRAIZOiZbTaJbFaRquhcNFN0J3xmhMReQ+v+Q1bO9AfqbWc+/SYWisEtQP9nRrDk/CaExF5B69JBgAgISzQaTen1FohSAizfbY8X8FrTkTk+Tx+aGFl8rRGHMrVwCBYqn0uZWl3OJ9O747XnIjIc3llMgAAJsGCY/nFyC7SQwLYNRSubP/Y0ACkRIXwfbWNeM2JiDyT1yYDZXQmM7I0OmRqdNZZ826/Ud36WSGVIF6tQpxaxaFsVcRrTkTkWbw+GShjEUUUGc3QGEzQGEwwCAIEiwiZVAKlTAa1UgG1UoFQfzmnu3UQXnMiIs/gM8kAERERVY4vZomIiHwckwEiIiIfx2SAiIjIxzEZICIi8nFMBoiIiHwckwEiIiIfx2SAiIjIxzEZICIi8nFMBoiIiHwckwEiIiIfx2SAiIjIxzEZICIi8nFMBoiIiHwckwEiIiIfx2SAiIjIxzEZICIi8nFMBoiIiHwckwEiIiIfx2SAiIjIxzEZICIi8nFMBoiIiHwckwEiIiIfx2SAiIjIxzEZICIi8nH/B49JaebVx10AAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.my_utiles import plot_graph\n",
    "plot_graph(graph_x, graph_edge_index, graph_edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:38:09] Explicit valence for atom # 3 O, 3, is greater than permitted\n"
     ]
    },
    {
     "ename": "AtomValenceException",
     "evalue": "Explicit valence for atom # 3 O, 3, is greater than permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAtomValenceException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m smiles \u001b[38;5;241m=\u001b[39m \u001b[43mgraph2smiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_edge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMILES:\u001b[39m\u001b[38;5;124m\"\u001b[39m, smiles)\n",
      "File \u001b[0;32m/datalake/datastore1/yang/graph-gpt/./src/utils/my_utiles.py:72\u001b[0m, in \u001b[0;36mgraph2smiles\u001b[0;34m(edge_index, edge_attr, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m             bond_obj\u001b[38;5;241m.\u001b[39mSetStereo(Chem\u001b[38;5;241m.\u001b[39mBondStereo\u001b[38;5;241m.\u001b[39mSTEREOTRANS)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Generate the SMILES string\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpdatePropertyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m Chem\u001b[38;5;241m.\u001b[39mSanitizeMol(mol)  \u001b[38;5;66;03m# Ensure the molecule is valid\u001b[39;00m\n\u001b[1;32m     74\u001b[0m smiles \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mMolToSmiles(mol, canonical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAtomValenceException\u001b[0m: Explicit valence for atom # 3 O, 3, is greater than permitted"
     ]
    }
   ],
   "source": [
    "smiles = graph2smiles(graph_edge_index, graph_edge_attr, graph_x)\n",
    "print(\"SMILES:\", smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Convert the SMILES string to a molecule object\n",
    "molecule = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Draw the molecule\n",
    "Draw.MolToImage(molecule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import fire\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.cuda.amp import GradScaler\n",
    "# import deepspeed\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from pprint import pprint, pformat\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from timm.utils import ModelEmaV3\n",
    "from timm.models import load_checkpoint\n",
    "from timm.utils.model import unwrap_model, get_state_dict\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ModuleNotFoundError:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-10 15:22:34,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlvsym'\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `shm_open'\n",
      "/home/yang/miniconda3/envs/graph_gpt/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `shm_unlink'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "from src.data import (\n",
    "    collator,\n",
    "    vocab_builder,\n",
    "    tokenizer,\n",
    "    read_dataset,\n",
    "    OdpsTableIterableDataset,\n",
    ")\n",
    "from src.models import (\n",
    "    GraphGPTConfig,\n",
    "    GraphGPTCausal,\n",
    "    GraphGPT2Config,\n",
    "    GraphGPT2Causal,\n",
    "    GraphBertConfig,\n",
    "    GraphBertForMaskedLM,\n",
    ")\n",
    "from src.utils import (\n",
    "    conf_utils,\n",
    "    loss_utils,\n",
    "    loader_utils,\n",
    "    tokenizer_utils,\n",
    "    modules_utils,\n",
    "    misc_utils,\n",
    "    print_trainable_parameters,\n",
    "    print_params,\n",
    "    inspect_tokenization_results,\n",
    "    set_up_shuffle_and_sampler,\n",
    "    worker_init_fn_seed,\n",
    ")\n",
    "\n",
    "dict_models = {\n",
    "    \"graphgpt2\": (GraphGPT2Causal, GraphGPT2Config),\n",
    "    \"graphgpt\": (GraphGPTCausal, GraphGPTConfig),\n",
    "    \"graphbert\": (GraphBertForMaskedLM, GraphBertConfig),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir: str = \"../data/OGB\"\n",
    "tables: str = \"\"\n",
    "# deepspeed_config = \"./examples/ds_config2_pt.json\"\n",
    "intermediate_size = 0\n",
    "num_attention_heads = 0\n",
    "hidden_size = 512\n",
    "num_hidden_layers = 8\n",
    "task_type='pretrain'\n",
    "causal_attention = 1\n",
    "lr=3e-4\n",
    "model_type = 'graphgpt'\n",
    "output_dir='./exp/models/pcqm4m-v2/test'\n",
    "pretrain_cpt = '/datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1'\n",
    "samples_per_saving=1000000\n",
    "\n",
    "batch_size = 1024\n",
    "stack_method = 'short'\n",
    "\n",
    "pack_tokens = 0\n",
    "max_position_embeddings = 1024\n",
    "\n",
    "task_type='pretrain'\n",
    "total_tokens=1e9\n",
    "batch_size = 1024\n",
    "warmup_tokens=1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 512 intermediate_size: 2048 num_attention_heads: 8 num_hidden_layers: 8 causal_attention: 1\n",
      "gpu_name: NVIDIA RTX A6000 GraphModel: <class 'src.models.graphgpt.modeling_graphgpt.GraphGPTCausal'> GraphModelConfig: <class 'src.models.graphgpt.configuration_graphgpt.GraphGPTConfig'>\n"
     ]
    }
   ],
   "source": [
    "use_tb_writer = False           # use tensorboard writer\n",
    "use_ema = False # False # use exponential moving average to smooth model\n",
    "use_deepspeed = False # True # use deepspeed for training, good to set scheduler\n",
    "if (intermediate_size == 0) and (num_attention_heads == 0): # True\n",
    "    (\n",
    "        hidden_size,\n",
    "        intermediate_size,\n",
    "        num_attention_heads,\n",
    "        num_hidden_layers,\n",
    "    ) = modules_utils.set_up_model_architect(\n",
    "        hidden_size=hidden_size, num_hidden_layers=num_hidden_layers # 768 24 related to model names intermediate_size = hidden_size * 4, num_attention_heads = hidden_size // 64\n",
    "    )# 768 3072 12 24\n",
    "causal_attention = 0 if task_type == \"pretrain-mlm\" else causal_attention\n",
    "print('hidden_size:', hidden_size, 'intermediate_size:', intermediate_size, 'num_attention_heads:', num_attention_heads, 'num_hidden_layers:', num_hidden_layers, 'causal_attention:', causal_attention) # 768 3072 12 24 1\n",
    "\n",
    "\n",
    "# #########################\n",
    "# betas = (0.9, 0.95) # used in AdamW optimizer, important for config beta\n",
    "# #########################\n",
    "# # lr * 0.1 -> from llama2 pre-train settings\n",
    "# min_lr = lr * 0.1 if use_deepspeed else 0    # used in scheduler, when not using deepspeed.\n",
    "# #########################\n",
    "gpu_name = torch.cuda.get_device_name()\n",
    "GraphModel, GraphModelConfig = dict_models[model_type] # Not instantiate yet\n",
    "print('gpu_name:', gpu_name, 'GraphModel:', GraphModel, 'GraphModelConfig:', GraphModelConfig) \n",
    "\n",
    "if os.path.exists(os.path.join(output_dir, \"log.csv\")):\n",
    "    print(\n",
    "        f\"log file {os.path.join(output_dir, 'log.csv')} exists, resume training from {output_dir} instead of initializing from pre-train ckp {pretrain_cpt}!\"\n",
    "    )\n",
    "    pretrain_cpt = output_dir\n",
    "\n",
    "\n",
    "# # 0. init distributed train and get gpu/device info\n",
    "# dist.init_process_group(backend=\"nccl\", init_method=\"env://\")  # for distributed training\n",
    "# dist.barrier() # for sync training\n",
    "# world_size = dist.get_world_size() # 1 # number of GPUs\n",
    "# rank = dist.get_rank() # 0 # current GPU index\n",
    "# local_rank = os.environ.get(\"LOCAL_RANK\") # 0 # current GPU index local to the node\n",
    "# print(f\"\\nworld size: {world_size}, rank: {rank}, local rank: {local_rank}\") # 1 0 0\n",
    "# rnd_seed = torch.random.initial_seed() - rank\n",
    "# random.seed(rnd_seed)\n",
    "# print(f\"seed random with {rnd_seed}\") # 1234\n",
    "# steps_per_saving = samples_per_saving // (world_size * batch_size) # 1000000 // (1 * 1024) = 976\n",
    "# print(f\"\\nsteps_per_saving: {steps_per_saving}\") # 976\n",
    "# params = print_params(**locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attr_world_identifier': 'molecule',\n",
      " 'data_dir': './data/OGB',\n",
      " 'dataset': 'PCQM4Mv2',\n",
      " 'ensemble_datasets': [],\n",
      " 'label_tokens_to_pad': ['<icl>'],\n",
      " 'name_or_path': './data/OGB/pcqm4m-v2',\n",
      " 'pretrain_mlm': {'info': 'name->polynomial|cosine|fixed,power->3/2/1/0.5',\n",
      "                  'name': 'polynomial',\n",
      "                  'params': {'fixed_ratio': 0.7,\n",
      "                             'mtp': [0.8, 0, 0.2],\n",
      "                             'power': 1}},\n",
      " 'sampling': None,\n",
      " 'semantics': {'attr_assignment': 'first',\n",
      "               'attr_shuffle': False,\n",
      "               'common': {'numbers': ['<e>',\n",
      "                                      '<.>',\n",
      "                                      '<->',\n",
      "                                      '<0>',\n",
      "                                      '<1>',\n",
      "                                      '<2>',\n",
      "                                      '<3>',\n",
      "                                      '<4>',\n",
      "                                      '<5>',\n",
      "                                      '<6>',\n",
      "                                      '<7>',\n",
      "                                      '<8>',\n",
      "                                      '<9>'],\n",
      "                          'reserved_token': ['semantics_0',\n",
      "                                             'semantics_1',\n",
      "                                             'semantics_2',\n",
      "                                             'semantics_3',\n",
      "                                             'semantics_4',\n",
      "                                             'semantics_5',\n",
      "                                             'semantics_6',\n",
      "                                             'semantics_7',\n",
      "                                             'semantics_8',\n",
      "                                             'semantics_9']},\n",
      "               'edge': {'continuous': None,\n",
      "                        'dim': 3,\n",
      "                        'discrete': 'edge_attr',\n",
      "                        'ignored_val': None},\n",
      "               'graph': {'continuous': None,\n",
      "                         'discrete': None,\n",
      "                         'ignored_val': None},\n",
      "               'instructions': {'enable': False,\n",
      "                                'func': [{'mask_ratio': 0,\n",
      "                                          'name': 'homo_lumo',\n",
      "                                          'valid': 1},\n",
      "                                         {'name': 'cepdb_prop_all',\n",
      "                                          'valid': 0}],\n",
      "                                'name': 'molecule'},\n",
      "               'node': {'continuous': None,\n",
      "                        'dim': 9,\n",
      "                        'discrete': 'x',\n",
      "                        'ignored_val': None}},\n",
      " 'structure': {'common': {'icl_token': '<icl>',\n",
      "                          'mask_token': '<mask>',\n",
      "                          'reserved_token': ['structure_0',\n",
      "                                             'structure_1',\n",
      "                                             'structure_2',\n",
      "                                             'structure_3',\n",
      "                                             'structure_4',\n",
      "                                             'structure_5',\n",
      "                                             'structure_6',\n",
      "                                             'structure_7',\n",
      "                                             'structure_8',\n",
      "                                             'structure_9'],\n",
      "                          'sep_token': '<sep>'},\n",
      "               'edge': {'bi_token': '<edge_bi>',\n",
      "                        'in_token': '<edge_in>',\n",
      "                        'jump_token': '<edge_jump>',\n",
      "                        'out_token': '<edge_out>',\n",
      "                        'remove_edge_type_token': True},\n",
      "               'graph': {'summary_token': '<gsum>'},\n",
      "               'node': {'bos_token': '<bos>',\n",
      "                        'cyclic': 1,\n",
      "                        'eos_token': '<eos>',\n",
      "                        'new_node_token': '<new>',\n",
      "                        'node_scope': 512,\n",
      "                        'scope_base': 512},\n",
      "               'nx': {'enable': False,\n",
      "                      'func': [{'name': 'degree', 'valid': 0},\n",
      "                               {'name': 'triangles', 'valid': 0},\n",
      "                               {'name': 'shortest_path', 'valid': 0},\n",
      "                               {'name': 'shortest_path_length', 'valid': 0},\n",
      "                               {'name': 'eulerian_path', 'valid': 1}]}},\n",
      " 'task_type': 'pretrain',\n",
      " 'tokenizer_class': 'StackedGSTTokenizer',\n",
      " 'vocab_file': 'vocab512_stacked'}\n"
     ]
    }
   ],
   "source": [
    "# tokenizer config loading\n",
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = \"./zhang_test/tokenizer_config.json\"\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    tokenizer_config = json.load(json_file)\n",
    "\n",
    "# Print the loaded data\n",
    "pprint(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked_feat: 13, next_n_token: 13, embed_dim: 0\n"
     ]
    }
   ],
   "source": [
    "# 1.1 read configuration\n",
    "assert \"pretrain\" in tokenizer_config[\"task_type\"]\n",
    "assert (\n",
    "    tokenizer_config[\"semantics\"][\"attr_assignment\"]   # first\n",
    "    in tokenizer_utils.ATTR_ASSIGNMENT_TYPES   # ATTR_ASSIGNMENT_TYPES = {\"first\", \"last\", \"random\", \"all\", \"mix\"}\n",
    ")\n",
    "# pprint(tokenizer_config)\n",
    "if tokenizer_config[\"tokenizer_class\"] == \"StackedGSTTokenizer\":\n",
    "    attr_dim = (\n",
    "        tokenizer_config[\"semantics\"][\"edge\"][\"dim\"] # 3\n",
    "        + tokenizer_config[\"semantics\"][\"node\"][\"dim\"] # 9\n",
    "    ) # 12\n",
    "    assert stack_method in (\"short\", \"long\", None), f\"stack_method: {stack_method}\" # short\n",
    "    if tokenizer_config[\"structure\"][\"edge\"][\"remove_edge_type_token\"]: # True\n",
    "        stacked_feat = 1 + attr_dim\n",
    "    else:\n",
    "        stacked_feat = 2 + attr_dim\n",
    "    next_n_token = stacked_feat\n",
    "else:\n",
    "    stacked_feat = 1\n",
    "    next_n_token = 1 # maybe how many pack of tokens to predict\n",
    "embed_dim = tokenizer_config[\"semantics\"][\"node\"].get(\n",
    "    \"embed_dim\", 0\n",
    ") + tokenizer_config[\"semantics\"][\"edge\"].get(\"embed_dim\", 0) # 0\n",
    "print(\n",
    "    f\"stacked_feat: {stacked_feat}, next_n_token: {next_n_token}, embed_dim: {embed_dim}\" # 13 13 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset PCQM4Mv2 ...\n",
      "\n",
      "dataset._data -> Data(edge_index=[2, 109093626], edge_attr=[109093626, 3], x=[52970652, 9], y=[3746620])\n",
      "In pre-train mode, set all valid data's y to nan!\n",
      "Before setting, y has 294469 NANs\n",
      "After setting, y has 368014 NANs\n",
      "Default process group has not been initialized, please make sure to call init_process_group.\n",
      "\n",
      "Raw indices: 3746620, Removed indices: 0, New indices: 3746620\n",
      "\n",
      "Raw indices: 3746620, Removed indices: 294469, New indices: 3452151\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "[Warning] permute_nodes enabled! edge_attr remains the same; edge_index and node-attrs will be affected!\n",
      "\n",
      "[2024-12-10 15:23:05.097728] NOT RESET samples of GraphsMapDataset of 3452151 graphs for epoch None!\n",
      "idx_tuple: None\n",
      "(0, Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1, 1], num_nodes=18, idx=0, idx_of_ds=0))\n"
     ]
    }
   ],
   "source": [
    "# 1.2 get graph dataset\n",
    "dataset, raw_dataset = read_dataset(\n",
    "    name=tokenizer_config[\"dataset\"],   # PCQM4Mv2\n",
    "    # for local data file reading\n",
    "    data_dir=data_dir,   # './data/OGB'\n",
    "    sampling_config=tokenizer_config[\"sampling\"],    # None\n",
    "    # for odps data reading\n",
    "    table=tables,   # \"\"\n",
    "    edge_dim=tokenizer_config[\"semantics\"][\"edge\"][\"dim\"],    # 3\n",
    "    node_dim=tokenizer_config[\"semantics\"][\"node\"][\"dim\"],    # 9\n",
    "    mode=\"train\",\n",
    "    # general\n",
    "    pretrain_mode=True,\n",
    "    # return_valid_test=True,\n",
    "    ensemble_datasets=tokenizer_config.get(\"ensemble_datasets\", []),    # []\n",
    ")\n",
    "reset_samples_per_epoch = (   # what is this  # None for PCQM4Mv2\n",
    "    dataset.reset_samples_per_epoch\n",
    "    if hasattr(dataset, \"reset_samples_per_epoch\")\n",
    "    else False\n",
    ")\n",
    "if isinstance(dataset, IterableDataset):\n",
    "    print(next(iter(dataset))) \n",
    "else: # True\n",
    "    idx = dataset.sampler[0] # (0, Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1, 1], num_nodes=18, idx=0, idx_of_ds=0))\n",
    "    print(dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.data.dataset_map.GraphsMapDataset object at 0x7f3af33bf130>\n",
      "length of dataset: 3452151\n",
      "(1, Data(edge_index=[2, 34], edge_attr=[34, 3], x=[17, 9], y=[1, 1], num_nodes=17, idx=1, idx_of_ds=0))\n",
      "(2, Data(edge_index=[2, 32], edge_attr=[32, 3], x=[16, 9], y=[1, 1], num_nodes=16, idx=2, idx_of_ds=0))\n",
      "####################################################################################################\n",
      "example\n",
      "edge_index:  tensor([[11,  8,  8,  6,  6,  2,  2,  5,  5, 12, 12, 13,  5, 16, 16,  1,  1, 14,\n",
      "         14, 15, 15, 10, 10,  7,  7,  0,  0,  9,  0,  4,  7,  3, 14,  6],\n",
      "        [ 8, 11,  6,  8,  2,  6,  5,  2, 12,  5, 13, 12, 16,  5,  1, 16, 14,  1,\n",
      "         15, 14, 10, 15,  7, 10,  0,  7,  9,  0,  4,  0,  3,  7,  6, 14]])\n",
      "edge_attr:  tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 2, 1],\n",
      "        [1, 2, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [0, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [1, 0, 1],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [3, 0, 1],\n",
      "        [3, 0, 1]])\n",
      "x:  tensor([[5, 0, 3, 5, 1, 0, 1, 0, 0],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 1, 1],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [6, 0, 3, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
      "        [5, 0, 3, 5, 1, 0, 1, 0, 0],\n",
      "        [7, 0, 2, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 1, 1],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [5, 0, 4, 5, 3, 0, 2, 0, 0],\n",
      "        [7, 0, 2, 5, 0, 0, 1, 0, 0],\n",
      "        [7, 0, 1, 5, 0, 0, 1, 0, 0],\n",
      "        [5, 0, 3, 5, 0, 0, 1, 1, 1]])\n",
      "y:  tensor([[4.4110]])\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print('length of dataset:', len(dataset))\n",
    "print(dataset[1])\n",
    "print(dataset[2])\n",
    "print(\"#\" * 100)\n",
    "print(\"example\")\n",
    "print(\"edge_index: \", dataset[1][1].edge_index)\n",
    "print(\"edge_attr: \", dataset[1][1].edge_attr)\n",
    "print(\"x: \", dataset[1][1].x)\n",
    "print(\"y: \", dataset[1][1].y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index type:  <class 'torch.Tensor'> dtype:  torch.int64\n",
      "edge_attr type:  <class 'torch.Tensor'> dtype:  torch.int64\n",
      "x type:  <class 'torch.Tensor'> dtype:  torch.int64\n",
      "y type:  <class 'torch.Tensor'> dtype:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(\"edge_index type: \", type(dataset[1][1].edge_index), \"dtype: \", dataset[1][1].edge_index.dtype)\n",
    "print(\"edge_attr type: \", type(dataset[1][1].edge_attr), \"dtype: \", dataset[1][1].edge_attr.dtype if dataset[1][1].edge_attr is not None else \"None\")\n",
    "print(\"x type: \", type(dataset[1][1].x), \"dtype: \", dataset[1][1].x.dtype)\n",
    "print(\"y type: \", type(dataset[1][1].y), \"dtype: \", dataset[1][1].y.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cc1ccc(C2Cc3cnccc3NC2=O)cc1\n"
     ]
    }
   ],
   "source": [
    "example_graph = dataset[0][1]\n",
    "from src.utils.my_utiles import graph2smiles\n",
    "smiles = graph2smiles(example_graph.edge_index, example_graph.edge_attr, example_graph.x)\n",
    "print(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-10 01:56:52.431594] Vocab is already built and saved in ./data/OGB/pcqm4m-v2/vocab512_stacked!\n",
      "[2024-12-10 01:56:52.432030] Loading vocab from ./data/OGB/pcqm4m-v2/vocab512_stacked ...\n",
      "[2024-12-10 01:56:52.435351]\n",
      "{   '0': 22,\n",
      "    '1': 23,\n",
      "    '10': 32,\n",
      "    '100': 122,\n",
      "    '101': 123,\n",
      "    '102': 124,\n",
      "    '103': 125,\n",
      "    '104': 126,\n",
      "    '105': 127,\n",
      "    '106': 128,\n",
      "    '107': 129,\n",
      "    '108': 130,\n",
      "    '109': 131,\n",
      "    '11': 33,\n",
      "    '110': 132,\n",
      "    '111': 133,\n",
      "    '112': 134,\n",
      "    '113': 135,\n",
      "    '114': 136,\n",
      "    '115': 137,\n",
      "    '116': 138,\n",
      "    '117': 139,\n",
      "    '118': 140,\n",
      "    '119': 141,\n",
      "    '12': 34,\n",
      "    '120': 142,\n",
      "    '121': 143,\n",
      "    '122': 144,\n",
      "    '123': 145,\n",
      "    '124': 146,\n",
      "    '125': 147,\n",
      "    '126': 148,\n",
      "    '127': 149,\n",
      "    '128': 150,\n",
      "    '129': 151,\n",
      "    '13': 35,\n",
      "    '130': 152,\n",
      "    '131': 153,\n",
      "    '132': 154,\n",
      "    '133': 155,\n",
      "    '134': 156,\n",
      "    '135': 157,\n",
      "    '136': 158,\n",
      "    '137': 159,\n",
      "    '138': 160,\n",
      "    '139': 161,\n",
      "    '14': 36,\n",
      "    '140': 162,\n",
      "    '141': 163,\n",
      "    '142': 164,\n",
      "    '143': 165,\n",
      "    '144': 166,\n",
      "    '145': 167,\n",
      "    '146': 168,\n",
      "    '147': 169,\n",
      "    '148': 170,\n",
      "    '149': 171,\n",
      "    '15': 37,\n",
      "    '150': 172,\n",
      "    '151': 173,\n",
      "    '152': 174,\n",
      "    '153': 175,\n",
      "    '154': 176,\n",
      "    '155': 177,\n",
      "    '156': 178,\n",
      "    '157': 179,\n",
      "    '158': 180,\n",
      "    '159': 181,\n",
      "    '16': 38,\n",
      "    '160': 182,\n",
      "    '161': 183,\n",
      "    '162': 184,\n",
      "    '163': 185,\n",
      "    '164': 186,\n",
      "    '165': 187,\n",
      "    '166': 188,\n",
      "    '167': 189,\n",
      "    '168': 190,\n",
      "    '169': 191,\n",
      "    '17': 39,\n",
      "    '170': 192,\n",
      "    '171': 193,\n",
      "    '172': 194,\n",
      "    '173': 195,\n",
      "    '174': 196,\n",
      "    '175': 197,\n",
      "    '176': 198,\n",
      "    '177': 199,\n",
      "    '178': 200,\n",
      "    '179': 201,\n",
      "    '18': 40,\n",
      "    '180': 202,\n",
      "    '181': 203,\n",
      "    '182': 204,\n",
      "    '183': 205,\n",
      "    '184': 206,\n",
      "    '185': 207,\n",
      "    '186': 208,\n",
      "    '187': 209,\n",
      "    '188': 210,\n",
      "    '189': 211,\n",
      "    '19': 41,\n",
      "    '190': 212,\n",
      "    '191': 213,\n",
      "    '192': 214,\n",
      "    '193': 215,\n",
      "    '194': 216,\n",
      "    '195': 217,\n",
      "    '196': 218,\n",
      "    '197': 219,\n",
      "    '198': 220,\n",
      "    '199': 221,\n",
      "    '2': 24,\n",
      "    '20': 42,\n",
      "    '200': 222,\n",
      "    '201': 223,\n",
      "    '202': 224,\n",
      "    '203': 225,\n",
      "    '204': 226,\n",
      "    '205': 227,\n",
      "    '206': 228,\n",
      "    '207': 229,\n",
      "    '208': 230,\n",
      "    '209': 231,\n",
      "    '21': 43,\n",
      "    '210': 232,\n",
      "    '211': 233,\n",
      "    '212': 234,\n",
      "    '213': 235,\n",
      "    '214': 236,\n",
      "    '215': 237,\n",
      "    '216': 238,\n",
      "    '217': 239,\n",
      "    '218': 240,\n",
      "    '219': 241,\n",
      "    '22': 44,\n",
      "    '220': 242,\n",
      "    '221': 243,\n",
      "    '222': 244,\n",
      "    '223': 245,\n",
      "    '224': 246,\n",
      "    '225': 247,\n",
      "    '226': 248,\n",
      "    '227': 249,\n",
      "    '228': 250,\n",
      "    '229': 251,\n",
      "    '23': 45,\n",
      "    '230': 252,\n",
      "    '231': 253,\n",
      "    '232': 254,\n",
      "    '233': 255,\n",
      "    '234': 256,\n",
      "    '235': 257,\n",
      "    '236': 258,\n",
      "    '237': 259,\n",
      "    '238': 260,\n",
      "    '239': 261,\n",
      "    '24': 46,\n",
      "    '240': 262,\n",
      "    '241': 263,\n",
      "    '242': 264,\n",
      "    '243': 265,\n",
      "    '244': 266,\n",
      "    '245': 267,\n",
      "    '246': 268,\n",
      "    '247': 269,\n",
      "    '248': 270,\n",
      "    '249': 271,\n",
      "    '25': 47,\n",
      "    '250': 272,\n",
      "    '251': 273,\n",
      "    '252': 274,\n",
      "    '253': 275,\n",
      "    '254': 276,\n",
      "    '255': 277,\n",
      "    '256': 278,\n",
      "    '257': 279,\n",
      "    '258': 280,\n",
      "    '259': 281,\n",
      "    '26': 48,\n",
      "    '260': 282,\n",
      "    '261': 283,\n",
      "    '262': 284,\n",
      "    '263': 285,\n",
      "    '264': 286,\n",
      "    '265': 287,\n",
      "    '266': 288,\n",
      "    '267': 289,\n",
      "    '268': 290,\n",
      "    '269': 291,\n",
      "    '27': 49,\n",
      "    '270': 292,\n",
      "    '271': 293,\n",
      "    '272': 294,\n",
      "    '273': 295,\n",
      "    '274': 296,\n",
      "    '275': 297,\n",
      "    '276': 298,\n",
      "    '277': 299,\n",
      "    '278': 300,\n",
      "    '279': 301,\n",
      "    '28': 50,\n",
      "    '280': 302,\n",
      "    '281': 303,\n",
      "    '282': 304,\n",
      "    '283': 305,\n",
      "    '284': 306,\n",
      "    '285': 307,\n",
      "    '286': 308,\n",
      "    '287': 309,\n",
      "    '288': 310,\n",
      "    '289': 311,\n",
      "    '29': 51,\n",
      "    '290': 312,\n",
      "    '291': 313,\n",
      "    '292': 314,\n",
      "    '293': 315,\n",
      "    '294': 316,\n",
      "    '295': 317,\n",
      "    '296': 318,\n",
      "    '297': 319,\n",
      "    '298': 320,\n",
      "    '299': 321,\n",
      "    '3': 25,\n",
      "    '30': 52,\n",
      "    '300': 322,\n",
      "    '301': 323,\n",
      "    '302': 324,\n",
      "    '303': 325,\n",
      "    '304': 326,\n",
      "    '305': 327,\n",
      "    '306': 328,\n",
      "    '307': 329,\n",
      "    '308': 330,\n",
      "    '309': 331,\n",
      "    '31': 53,\n",
      "    '310': 332,\n",
      "    '311': 333,\n",
      "    '312': 334,\n",
      "    '313': 335,\n",
      "    '314': 336,\n",
      "    '315': 337,\n",
      "    '316': 338,\n",
      "    '317': 339,\n",
      "    '318': 340,\n",
      "    '319': 341,\n",
      "    '32': 54,\n",
      "    '320': 342,\n",
      "    '321': 343,\n",
      "    '322': 344,\n",
      "    '323': 345,\n",
      "    '324': 346,\n",
      "    '325': 347,\n",
      "    '326': 348,\n",
      "    '327': 349,\n",
      "    '328': 350,\n",
      "    '329': 351,\n",
      "    '33': 55,\n",
      "    '330': 352,\n",
      "    '331': 353,\n",
      "    '332': 354,\n",
      "    '333': 355,\n",
      "    '334': 356,\n",
      "    '335': 357,\n",
      "    '336': 358,\n",
      "    '337': 359,\n",
      "    '338': 360,\n",
      "    '339': 361,\n",
      "    '34': 56,\n",
      "    '340': 362,\n",
      "    '341': 363,\n",
      "    '342': 364,\n",
      "    '343': 365,\n",
      "    '344': 366,\n",
      "    '345': 367,\n",
      "    '346': 368,\n",
      "    '347': 369,\n",
      "    '348': 370,\n",
      "    '349': 371,\n",
      "    '35': 57,\n",
      "    '350': 372,\n",
      "    '351': 373,\n",
      "    '352': 374,\n",
      "    '353': 375,\n",
      "    '354': 376,\n",
      "    '355': 377,\n",
      "    '356': 378,\n",
      "    '357': 379,\n",
      "    '358': 380,\n",
      "    '359': 381,\n",
      "    '36': 58,\n",
      "    '360': 382,\n",
      "    '361': 383,\n",
      "    '362': 384,\n",
      "    '363': 385,\n",
      "    '364': 386,\n",
      "    '365': 387,\n",
      "    '366': 388,\n",
      "    '367': 389,\n",
      "    '368': 390,\n",
      "    '369': 391,\n",
      "    '37': 59,\n",
      "    '370': 392,\n",
      "    '371': 393,\n",
      "    '372': 394,\n",
      "    '373': 395,\n",
      "    '374': 396,\n",
      "    '375': 397,\n",
      "    '376': 398,\n",
      "    '377': 399,\n",
      "    '378': 400,\n",
      "    '379': 401,\n",
      "    '38': 60,\n",
      "    '380': 402,\n",
      "    '381': 403,\n",
      "    '382': 404,\n",
      "    '383': 405,\n",
      "    '384': 406,\n",
      "    '385': 407,\n",
      "    '386': 408,\n",
      "    '387': 409,\n",
      "    '388': 410,\n",
      "    '389': 411,\n",
      "    '39': 61,\n",
      "    '390': 412,\n",
      "    '391': 413,\n",
      "    '392': 414,\n",
      "    '393': 415,\n",
      "    '394': 416,\n",
      "    '395': 417,\n",
      "    '396': 418,\n",
      "    '397': 419,\n",
      "    '398': 420,\n",
      "    '399': 421,\n",
      "    '4': 26,\n",
      "    '40': 62,\n",
      "    '400': 422,\n",
      "    '401': 423,\n",
      "    '402': 424,\n",
      "    '403': 425,\n",
      "    '404': 426,\n",
      "    '405': 427,\n",
      "    '406': 428,\n",
      "    '407': 429,\n",
      "    '408': 430,\n",
      "    '409': 431,\n",
      "    '41': 63,\n",
      "    '410': 432,\n",
      "    '411': 433,\n",
      "    '412': 434,\n",
      "    '413': 435,\n",
      "    '414': 436,\n",
      "    '415': 437,\n",
      "    '416': 438,\n",
      "    '417': 439,\n",
      "    '418': 440,\n",
      "    '419': 441,\n",
      "    '42': 64,\n",
      "    '420': 442,\n",
      "    '421': 443,\n",
      "    '422': 444,\n",
      "    '423': 445,\n",
      "    '424': 446,\n",
      "    '425': 447,\n",
      "    '426': 448,\n",
      "    '427': 449,\n",
      "    '428': 450,\n",
      "    '429': 451,\n",
      "    '43': 65,\n",
      "    '430': 452,\n",
      "    '431': 453,\n",
      "    '432': 454,\n",
      "    '433': 455,\n",
      "    '434': 456,\n",
      "    '435': 457,\n",
      "    '436': 458,\n",
      "    '437': 459,\n",
      "    '438': 460,\n",
      "    '439': 461,\n",
      "    '44': 66,\n",
      "    '440': 462,\n",
      "    '441': 463,\n",
      "    '442': 464,\n",
      "    '443': 465,\n",
      "    '444': 466,\n",
      "    '445': 467,\n",
      "    '446': 468,\n",
      "    '447': 469,\n",
      "    '448': 470,\n",
      "    '449': 471,\n",
      "    '45': 67,\n",
      "    '450': 472,\n",
      "    '451': 473,\n",
      "    '452': 474,\n",
      "    '453': 475,\n",
      "    '454': 476,\n",
      "    '455': 477,\n",
      "    '456': 478,\n",
      "    '457': 479,\n",
      "    '458': 480,\n",
      "    '459': 481,\n",
      "    '46': 68,\n",
      "    '460': 482,\n",
      "    '461': 483,\n",
      "    '462': 484,\n",
      "    '463': 485,\n",
      "    '464': 486,\n",
      "    '465': 487,\n",
      "    '466': 488,\n",
      "    '467': 489,\n",
      "    '468': 490,\n",
      "    '469': 491,\n",
      "    '47': 69,\n",
      "    '470': 492,\n",
      "    '471': 493,\n",
      "    '472': 494,\n",
      "    '473': 495,\n",
      "    '474': 496,\n",
      "    '475': 497,\n",
      "    '476': 498,\n",
      "    '477': 499,\n",
      "    '478': 500,\n",
      "    '479': 501,\n",
      "    '48': 70,\n",
      "    '480': 502,\n",
      "    '481': 503,\n",
      "    '482': 504,\n",
      "    '483': 505,\n",
      "    '484': 506,\n",
      "    '485': 507,\n",
      "    '486': 508,\n",
      "    '487': 509,\n",
      "    '488': 510,\n",
      "    '489': 511,\n",
      "    '49': 71,\n",
      "    '490': 512,\n",
      "    '491': 513,\n",
      "    '492': 514,\n",
      "    '493': 515,\n",
      "    '494': 516,\n",
      "    '495': 517,\n",
      "    '496': 518,\n",
      "    '497': 519,\n",
      "    '498': 520,\n",
      "    '499': 521,\n",
      "    '5': 27,\n",
      "    '50': 72,\n",
      "    '500': 522,\n",
      "    '501': 523,\n",
      "    '502': 524,\n",
      "    '503': 525,\n",
      "    '504': 526,\n",
      "    '505': 527,\n",
      "    '506': 528,\n",
      "    '507': 529,\n",
      "    '508': 530,\n",
      "    '509': 531,\n",
      "    '51': 73,\n",
      "    '510': 532,\n",
      "    '511': 533,\n",
      "    '52': 74,\n",
      "    '53': 75,\n",
      "    '54': 76,\n",
      "    '55': 77,\n",
      "    '56': 78,\n",
      "    '57': 79,\n",
      "    '58': 80,\n",
      "    '59': 81,\n",
      "    '6': 28,\n",
      "    '60': 82,\n",
      "    '61': 83,\n",
      "    '62': 84,\n",
      "    '63': 85,\n",
      "    '64': 86,\n",
      "    '65': 87,\n",
      "    '66': 88,\n",
      "    '67': 89,\n",
      "    '68': 90,\n",
      "    '69': 91,\n",
      "    '7': 29,\n",
      "    '70': 92,\n",
      "    '71': 93,\n",
      "    '72': 94,\n",
      "    '73': 95,\n",
      "    '74': 96,\n",
      "    '75': 97,\n",
      "    '76': 98,\n",
      "    '77': 99,\n",
      "    '78': 100,\n",
      "    '79': 101,\n",
      "    '8': 30,\n",
      "    '80': 102,\n",
      "    '81': 103,\n",
      "    '82': 104,\n",
      "    '83': 105,\n",
      "    '84': 106,\n",
      "    '85': 107,\n",
      "    '86': 108,\n",
      "    '87': 109,\n",
      "    '88': 110,\n",
      "    '89': 111,\n",
      "    '9': 31,\n",
      "    '90': 112,\n",
      "    '91': 113,\n",
      "    '92': 114,\n",
      "    '93': 115,\n",
      "    '94': 116,\n",
      "    '95': 117,\n",
      "    '96': 118,\n",
      "    '97': 119,\n",
      "    '98': 120,\n",
      "    '99': 121,\n",
      "    '<->': 546,\n",
      "    '<.>': 545,\n",
      "    '<0>': 547,\n",
      "    '<1>': 548,\n",
      "    '<2>': 549,\n",
      "    '<3>': 550,\n",
      "    '<4>': 551,\n",
      "    '<5>': 552,\n",
      "    '<6>': 553,\n",
      "    '<7>': 554,\n",
      "    '<8>': 555,\n",
      "    '<9>': 556,\n",
      "    '<bos>': 20,\n",
      "    '<e>': 544,\n",
      "    '<edge_bi>': 17,\n",
      "    '<edge_in>': 15,\n",
      "    '<edge_jump>': 18,\n",
      "    '<edge_out>': 16,\n",
      "    '<eos>': 19,\n",
      "    '<gsum>': 14,\n",
      "    '<icl>': 2,\n",
      "    '<label_pad>': -100,\n",
      "    '<mask>': 1,\n",
      "    '<new>': 21,\n",
      "    '<sep>': 3,\n",
      "    'molecule#edge#0': 740,\n",
      "    'molecule#edge#0#0': 743,\n",
      "    'molecule#edge#0#1': 744,\n",
      "    'molecule#edge#0#2': 745,\n",
      "    'molecule#edge#0#3': 746,\n",
      "    'molecule#edge#0#4': 747,\n",
      "    'molecule#edge#1': 741,\n",
      "    'molecule#edge#1#0': 748,\n",
      "    'molecule#edge#1#1': 749,\n",
      "    'molecule#edge#1#2': 750,\n",
      "    'molecule#edge#1#3': 751,\n",
      "    'molecule#edge#1#4': 752,\n",
      "    'molecule#edge#1#5': 753,\n",
      "    'molecule#edge#2': 742,\n",
      "    'molecule#edge#2#0': 754,\n",
      "    'molecule#edge#2#1': 755,\n",
      "    'molecule#node#0': 557,\n",
      "    'molecule#node#0#0': 566,\n",
      "    'molecule#node#0#1': 567,\n",
      "    'molecule#node#0#10': 568,\n",
      "    'molecule#node#0#100': 569,\n",
      "    'molecule#node#0#101': 570,\n",
      "    'molecule#node#0#102': 571,\n",
      "    'molecule#node#0#103': 572,\n",
      "    'molecule#node#0#104': 573,\n",
      "    'molecule#node#0#105': 574,\n",
      "    'molecule#node#0#106': 575,\n",
      "    'molecule#node#0#107': 576,\n",
      "    'molecule#node#0#108': 577,\n",
      "    'molecule#node#0#109': 578,\n",
      "    'molecule#node#0#11': 579,\n",
      "    'molecule#node#0#110': 580,\n",
      "    'molecule#node#0#111': 581,\n",
      "    'molecule#node#0#112': 582,\n",
      "    'molecule#node#0#113': 583,\n",
      "    'molecule#node#0#114': 584,\n",
      "    'molecule#node#0#115': 585,\n",
      "    'molecule#node#0#116': 586,\n",
      "    'molecule#node#0#117': 587,\n",
      "    'molecule#node#0#118': 588,\n",
      "    'molecule#node#0#12': 589,\n",
      "    'molecule#node#0#13': 590,\n",
      "    'molecule#node#0#14': 591,\n",
      "    'molecule#node#0#15': 592,\n",
      "    'molecule#node#0#16': 593,\n",
      "    'molecule#node#0#17': 594,\n",
      "    'molecule#node#0#18': 595,\n",
      "    'molecule#node#0#19': 596,\n",
      "    'molecule#node#0#2': 597,\n",
      "    'molecule#node#0#20': 598,\n",
      "    'molecule#nod ......\n",
      "label token id to be converted to -100 is {2}\n"
     ]
    }
   ],
   "source": [
    "add_eos = False\n",
    "rank = 0\n",
    "stack_method = \"short\"\n",
    "# 1.3 build vocab and then init tokenizer from the tokenization config\n",
    "vocab_builder.build_vocab(raw_dataset, tokenizer_config, rank) # build vocab from file or scratch\n",
    "tokenizer_cls = getattr(tokenizer, tokenizer_config[\"tokenizer_class\"]) # StackGSTTokenizer, custom defined\n",
    "gtokenizer = tokenizer_cls(\n",
    "    tokenizer_config, add_eos=add_eos, stack_method=stack_method # instantiate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<src.data.tokenizer.StackedGSTTokenizer object at 0x7ff2ef2c2430>\n"
     ]
    }
   ],
   "source": [
    "print(gtokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting tokenization results!\n",
      "Tokenize graph:\n",
      "Data(edge_index=[2, 40], edge_attr=[40, 3], x=[18, 9], y=[1, 1], num_nodes=18, idx=0, idx_of_ds=0)\n",
      "[Warning] Set eos_idx to 100000000 for task pretrain!\n",
      "\n",
      "Tokens:\n",
      "[['22',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#2',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0',\n",
      "  'molecule#edge#1',\n",
      "  'molecule#edge#2'],\n",
      " ['23',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#1',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['24',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['25',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['26',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['27',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['28',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['29',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['24',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['25',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['30',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#1',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['31',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['32',\n",
      "  'molecule#node#0#7',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#1',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['31',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['22',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#2',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['33',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['34',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['35',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['36',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['37',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#3',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['36',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['38',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['39',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['33',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1']]\n",
      "Labels:\n",
      "[['23',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#1',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['24',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['25',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['26',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['27',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['28',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['29',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['24',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['25',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['30',\n",
      "  'molecule#node#0#6',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#2',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#1',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['31',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['32',\n",
      "  'molecule#node#0#7',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#1',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['31',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#1',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['22',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#2',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['33',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['34',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['35',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['36',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['37',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#4',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#3',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#2',\n",
      "  'molecule#node#7#0',\n",
      "  'molecule#node#8#0',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['36',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#0',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#0'],\n",
      " ['38',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['39',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#1',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['33',\n",
      "  'molecule#node#0#5',\n",
      "  'molecule#node#1#0',\n",
      "  'molecule#node#2#3',\n",
      "  'molecule#node#3#5',\n",
      "  'molecule#node#4#0',\n",
      "  'molecule#node#5#0',\n",
      "  'molecule#node#6#1',\n",
      "  'molecule#node#7#1',\n",
      "  'molecule#node#8#1',\n",
      "  'molecule#edge#0#3',\n",
      "  'molecule#edge#1#0',\n",
      "  'molecule#edge#2#1'],\n",
      " ['<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>',\n",
      "  '<eos>']]\n",
      "embed:[]\n",
      "\n",
      "Inputs for model:\n",
      "{'attention_mask': [1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1,\n",
      "                    1],\n",
      " 'embed': array([], shape=(24, 0), dtype=float64),\n",
      " 'input_ids': [[44, 630, 687, 696, 709, 715, 724, 732, 736, 739, 740, 741, 742],\n",
      "               [45, 630, 685, 695, 709, 715, 725, 732, 736, 739, 743, 748, 754],\n",
      "               [46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "               [47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [48, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [49, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [50, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [51, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [52, 641, 685, 694, 709, 714, 725, 731, 736, 739, 743, 748, 755],\n",
      "               [53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 743, 748, 755],\n",
      "               [54, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "               [53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 744, 748, 755],\n",
      "               [44, 630, 687, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
      "               [55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "               [56, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [57, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [59, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "               [58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "               [60, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [61, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "               [55,\n",
      "                630,\n",
      "                685,\n",
      "                695,\n",
      "                709,\n",
      "                714,\n",
      "                724,\n",
      "                731,\n",
      "                737,\n",
      "                739,\n",
      "                746,\n",
      "                748,\n",
      "                755]],\n",
      " 'labels': [[45, 630, 685, 695, 709, 715, 725, 732, 736, 739, 743, 748, 754],\n",
      "            [46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "            [47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [48, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [49, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [50, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [51, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [52, 641, 685, 694, 709, 714, 725, 731, 736, 739, 743, 748, 755],\n",
      "            [53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 743, 748, 755],\n",
      "            [54, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "            [53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 744, 748, 755],\n",
      "            [44, 630, 687, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
      "            [55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "            [56, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [57, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [59, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "            [58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "            [60, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [61, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "            [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]],\n",
      " 'position_ids': [0,\n",
      "                  1,\n",
      "                  2,\n",
      "                  3,\n",
      "                  4,\n",
      "                  5,\n",
      "                  6,\n",
      "                  7,\n",
      "                  8,\n",
      "                  9,\n",
      "                  10,\n",
      "                  11,\n",
      "                  12,\n",
      "                  13,\n",
      "                  14,\n",
      "                  15,\n",
      "                  16,\n",
      "                  17,\n",
      "                  18,\n",
      "                  19,\n",
      "                  20,\n",
      "                  21,\n",
      "                  22,\n",
      "                  23]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_graph = dataset[0][1]\n",
    "from src.utils.my_utiles import graph2token2input\n",
    "import numpy as np\n",
    "token, label, embed, inputs = graph2token2input(example_graph, gtokenizer)\n",
    "\n",
    "print(\n",
    "    f\"\\nTokens:\\n{pformat(token)}\\nLabels:\\n{pformat(label)}\\nembed:{np.array(embed)}\\n\"\n",
    ")\n",
    "\n",
    "print(f\"Inputs for model:\\n{pformat(inputs)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'position_ids', 'labels', 'attention_mask', 'embed'])\n"
     ]
    }
   ],
   "source": [
    "from src.utils.my_utiles import convert_to_tensors\n",
    "\n",
    "tensor_inputs = convert_to_tensors(inputs)\n",
    "print(tensor_inputs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 24, 13])\n",
      "position_ids: torch.Size([1, 24])\n",
      "labels: torch.Size([1, 24, 13])\n",
      "attention_mask: torch.Size([1, 24])\n",
      "embed: torch.Size([1, 24, 0])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids:\", tensor_inputs[\"input_ids\"].shape)\n",
    "print(\"position_ids:\", tensor_inputs[\"position_ids\"].shape)\n",
    "print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "print(\"attention_mask:\", tensor_inputs[\"attention_mask\"].shape)\n",
    "print(\"embed:\", tensor_inputs[\"embed\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 44, 630, 687, 696, 709, 715, 724, 732, 736, 739, 740, 741, 742],\n",
      "         [ 45, 630, 685, 695, 709, 715, 725, 732, 736, 739, 743, 748, 754],\n",
      "         [ 46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [ 47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 48, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 49, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 50, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 51, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 52, 641, 685, 694, 709, 714, 725, 731, 736, 739, 743, 748, 755],\n",
      "         [ 53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 743, 748, 755],\n",
      "         [ 54, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "         [ 53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 744, 748, 755],\n",
      "         [ 44, 630, 687, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [ 55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [ 56, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 57, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 59, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [ 58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [ 60, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 61, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755]]])\n",
      "tensor([[[ 45, 630, 685, 695, 709, 715, 725, 732, 736, 739, 743, 748, 754],\n",
      "         [ 46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [ 47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 48, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 49, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 50, 641, 685, 694, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 51, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 46, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 47, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 52, 641, 685, 694, 709, 714, 725, 731, 736, 739, 743, 748, 755],\n",
      "         [ 53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 743, 748, 755],\n",
      "         [ 54, 652, 685, 691, 709, 714, 724, 731, 736, 738, 744, 748, 755],\n",
      "         [ 53, 630, 685, 695, 709, 714, 724, 731, 736, 739, 744, 748, 755],\n",
      "         [ 44, 630, 687, 696, 709, 715, 724, 732, 736, 739, 743, 748, 754],\n",
      "         [ 55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [ 56, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 57, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 59, 630, 685, 696, 709, 717, 724, 732, 736, 738, 743, 748, 754],\n",
      "         [ 58, 630, 685, 695, 709, 714, 724, 731, 737, 739, 743, 748, 754],\n",
      "         [ 60, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 61, 630, 685, 695, 709, 715, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 55, 630, 685, 695, 709, 714, 724, 731, 737, 739, 746, 748, 755],\n",
      "         [ 19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19,  19]]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_inputs[\"input_ids\"])\n",
    "print(tensor_inputs[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphGPTConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 20,\n",
      "  \"causal_attention\": true,\n",
      "  \"cls_token_id\": null,\n",
      "  \"dropout\": 0,\n",
      "  \"embed_dim\": 0,\n",
      "  \"embed_pdrop\": 0,\n",
      "  \"eos_token_id\": 19,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_scale_init_value\": 0,\n",
      "  \"loss_type\": null,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"mlp\": [],\n",
      "  \"mlp_pdrop\": 0,\n",
      "  \"model_type\": \"graphgpt\",\n",
      "  \"next_n_token\": 13,\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_neg\": null,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"path_pdrop\": 0,\n",
      "  \"pooling_method\": \"last\",\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000,\n",
      "  \"stack_method\": \"short\",\n",
      "  \"stacked_feat\": 13,\n",
      "  \"stacked_feat_agg_method\": \"gated\",\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 756\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"./zhang_test/model_config.pkl\", \"rb\") as file:  # \"rb\" mode for reading binary\n",
    "    config = pickle.load(file)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_deepspeed = True\n",
    "\n",
    "# # 2.2 create model\n",
    "# if use_deepspeed:\n",
    "#     deepspeed.init_distributed(\n",
    "#         dist_backend=\"nccl\", rank=rank, world_size=world_size\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT Applying dropout in backbone transformer\n",
      "Next-token-prediction changed to next/masked-13-tokens-prediction!\n",
      "trainable params: 37751808 || all params: 37751808 || trainable%: 100.0\n"
     ]
    }
   ],
   "source": [
    "model = GraphModel(config)\n",
    "\n",
    "\n",
    "# model.gradient_checkpointing_enable()\n",
    "# silence the warnings. Please re-enable for inference!\n",
    "model.config.use_cache = False\n",
    "print_trainable_parameters(model) # 235368960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from ckp /datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1/epoch_51\n",
      "inar:  [Errno 2] No such file or directory: '/datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1/epoch_51/model.pt'\n",
      "Processing zero checkpoint '/datalake/datastore1/yang/graph-gpt/exp/models/pcqm4m-v2/medium_ntp/pt_ns_h512_l8_b8192_mpe1024_tk1e9_gelu_pretrain3.3m_nmlm_mrlinear_mtp0.8_0_0.2_lr3e-4_adp0.1_pdp0_edp0_mdp0_lsi0_short_gated_wd0.1/epoch_51/global_step48830'\n",
      "Detected checkpoint of type zero stage 2, world_size: 1\n",
      "Parsing checkpoint created by deepspeed==0.15.1\n",
      "Reconstructed fp32 state dict with 77 params 37751808 elements\n",
      "[2024-12-10 01:56:54.509046] load ckp using DeepSpeed API `get_fp32_state_dict_from_zero_checkpoint`\n",
      "[2024-12-10 01:56:54.544139] init model params using pytorch `load_state_dict`\n",
      "missing keys: []\n",
      "unexpected_keys: []\n",
      "After loading weights from ckp:\n",
      "GraphGPTConfig {\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 20,\n",
      "  \"causal_attention\": true,\n",
      "  \"cls_token_id\": null,\n",
      "  \"dropout\": 0,\n",
      "  \"embed_dim\": 0,\n",
      "  \"embed_pdrop\": 0,\n",
      "  \"eos_token_id\": 19,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_scale_init_value\": 0,\n",
      "  \"loss_type\": null,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"mlp\": [],\n",
      "  \"mlp_pdrop\": 0,\n",
      "  \"model_type\": \"graphgpt\",\n",
      "  \"next_n_token\": 13,\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_neg\": null,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"path_pdrop\": 0,\n",
      "  \"pooling_method\": \"last\",\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000,\n",
      "  \"stack_method\": \"short\",\n",
      "  \"stacked_feat\": 13,\n",
      "  \"stacked_feat_agg_method\": \"gated\",\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 756\n",
      "}\n",
      "\n",
      "model-type: torch.float32\n",
      "\n",
      "GraphGPTCausal(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(756, 512, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-7): 8 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (up_proj): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (down_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (act_fn): GELUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=756, bias=False)\n",
      "  (stacked_feat_agg): StackedFeatAggregation(stacked_feat=13, hidden_size=512)\n",
      "  (next_n_token_head): Linear(in_features=512, out_features=6656, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2.21 load from ckp IF provided existing ckp and NOT resume from the ckp\n",
    "ckp, _ = misc_utils.get_latest_ckp(pretrain_cpt)\n",
    "print(f\"Loading pretrained weights from ckp {ckp}\")\n",
    "try:\n",
    "    # fn_model = os.path.join(ckp, \"../model_ema_best.pt\")\n",
    "    # if not os.path.isfile(fn_model):\n",
    "    fn_model = os.path.join(ckp, \"model.pt\")\n",
    "    stat_dict = torch.load(fn_model)\n",
    "    stat_dict = {\n",
    "        (k[7:] if k.startswith(\"module.\") else k): v for k, v in stat_dict.items()\n",
    "    }\n",
    "    print(f\"[{datetime.now()}] load ckp using torch API from:\\n{fn_model}\")\n",
    "except Exception as inst:\n",
    "    # print(type(inst))\n",
    "    # print(inst.args)\n",
    "    print(\"inar: \", inst)\n",
    "    from deepspeed.utils.zero_to_fp32 import (\n",
    "        get_fp32_state_dict_from_zero_checkpoint,\n",
    "    )\n",
    "    stat_dict = get_fp32_state_dict_from_zero_checkpoint(ckp)\n",
    "    print(\n",
    "        f\"[{datetime.now()}] load ckp using DeepSpeed API `get_fp32_state_dict_from_zero_checkpoint`\"\n",
    "    )\n",
    "\n",
    "for key in list(stat_dict.keys()):\n",
    "    if (\"score\" in key) and skip_keys:\n",
    "        stat_dict.pop(key)\n",
    "        print(f\"pop key {key} in stat_dict!\")\n",
    "missing_keys, unexpected_keys = model.load_state_dict(stat_dict, strict=True)\n",
    "print(\n",
    "    f\"[{datetime.now()}] init model params using pytorch `load_state_dict`\\n\"\n",
    "    f\"missing keys: {missing_keys}\\n\"\n",
    "    f\"unexpected_keys: {unexpected_keys}\\n\"\n",
    "    f\"After loading weights from ckp:\\n{model.config}\\nmodel-type: {model.dtype}\\n\\n{model}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([1, 24, 13])\n",
      "position_ids: torch.Size([1, 24])\n",
      "labels: torch.Size([1, 24, 13])\n",
      "attention_mask: torch.Size([1, 24])\n",
      "embed: torch.Size([1, 24, 0])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids:\", tensor_inputs[\"input_ids\"].shape)\n",
    "print(\"position_ids:\", tensor_inputs[\"position_ids\"].shape)\n",
    "print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "print(\"attention_mask:\", tensor_inputs[\"attention_mask\"].shape)\n",
    "print(\"embed:\", tensor_inputs[\"embed\"].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"device: {device}\")\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CausalLMOutputWithPast(loss=tensor(0.1592, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-6.8285e-01, -5.2476e-01, -7.8901e-01,  ..., -8.6922e-01,\n",
      "         -1.5787e-03,  4.5053e-01],\n",
      "        [-8.2714e+00, -8.2891e+00, -8.2824e+00,  ..., -8.2746e+00,\n",
      "         -3.3644e+00, -3.3576e+00],\n",
      "        [-4.5638e+00, -4.7213e+00, -4.6861e+00,  ..., -4.8072e+00,\n",
      "         -1.4092e+00, -1.0710e+00],\n",
      "        ...,\n",
      "        [ 3.0432e-01,  6.3430e-01,  9.7459e-02,  ..., -9.9691e-02,\n",
      "          2.0882e+00,  3.4079e-01],\n",
      "        [ 2.5485e+00,  2.9396e+00,  3.1794e+00,  ...,  3.0270e+00,\n",
      "          3.2834e+00,  6.0216e-01],\n",
      "        [-7.1706e-01, -8.3712e-01, -4.2776e-01,  ..., -1.1047e+00,\n",
      "          4.3890e+00,  2.1820e+00]], device='cuda:0', grad_fn=<ViewBackward0>), past_key_values=None, hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data = tensor_inputs\n",
    "input_ids = data[\"input_ids\"].to(device)\n",
    "attention_mask = data[\"attention_mask\"].to(device)\n",
    "labels = data[\"labels\"].to(device)\n",
    "inputs_raw_embeds = None\n",
    "if embed_dim > 0: # in tokenizer config\n",
    "    inputs_raw_embeds = data[\"embed\"].to(device)\n",
    "output = model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    labels=labels,\n",
    "    inputs_raw_embeds=inputs_raw_embeds,\n",
    ")  # Perform a single forward pass.\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: torch.Size([1, 24, 13])\n",
      "output: odict_keys(['loss', 'logits'])\n",
      "output: torch.Size([312, 756])\n"
     ]
    }
   ],
   "source": [
    "print(\"labels:\", tensor_inputs[\"labels\"].shape)\n",
    "print(\"output:\", output.keys())\n",
    "print(\"output:\", output[\"logits\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = torch.argmax(output[\"logits\"], dim=-1) \n",
    "reshaped_labels = predicted_labels.view(1, 24, 13)\n",
    "print(\"labels:\", tensor_inputs[\"labels\"])\n",
    "print(\"predicted_labels:\", reshaped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['23 45',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#4 696',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#2 716',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#2 732',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['24 46',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#1 725',\n",
      "  'molecule#node#6#2 732',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['25 47',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['24 46',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['27 49',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['28 50',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['29 51',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['24 46',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['25 47',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['30 52',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#1 725',\n",
      "  'molecule#node#6#2 732',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['31 53',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['32 54',\n",
      "  'molecule#node#0#7 652',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#1 691',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#0 738',\n",
      "  'molecule#edge#0#1 744',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['31 53',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#1 744',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['22 44',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#2 687',\n",
      "  'molecule#node#2#4 696',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#2 732',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['33 55',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#2 732',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#0 738',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['34 56',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['35 57',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['36 58',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['37 59',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#4 696',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#3 717',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#2 732',\n",
      "  'molecule#node#7#0 736',\n",
      "  'molecule#node#8#0 738',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['36 58',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#0 743',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#0 754'],\n",
      " ['38 60',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['39 61',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#1 715',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['33 55',\n",
      "  'molecule#node#0#5 630',\n",
      "  'molecule#node#1#0 685',\n",
      "  'molecule#node#2#3 695',\n",
      "  'molecule#node#3#5 709',\n",
      "  'molecule#node#4#0 714',\n",
      "  'molecule#node#5#0 724',\n",
      "  'molecule#node#6#1 731',\n",
      "  'molecule#node#7#1 737',\n",
      "  'molecule#node#8#1 739',\n",
      "  'molecule#edge#0#3 746',\n",
      "  'molecule#edge#1#0 748',\n",
      "  'molecule#edge#2#1 755'],\n",
      " ['<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19',\n",
      "  '<eos> 19']]\n"
     ]
    }
   ],
   "source": [
    "# File path to your vocabulary file\n",
    "vocab_file_path = \"/datalake/datastore1/yang/graph-gpt/data/OGB/pcqm4m-v2/vocab512_stacked\"\n",
    "\n",
    "# Step 1: Load the vocabulary\n",
    "def load_vocab(vocab_file):\n",
    "    \"\"\"Loads a vocabulary file and returns a dictionary mapping token IDs to tokens.\"\"\"\n",
    "    vocab = {}\n",
    "    with open(vocab_file, \"r\") as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            vocab[idx + 1] = line.strip()  # Remove newline characters\n",
    "    return vocab\n",
    "\n",
    "vocab = load_vocab(vocab_file_path)\n",
    "# pprint(vocab.keys())\n",
    "# Step 2: Convert predicted label IDs to tokens\n",
    "def convert_labels_to_tokens(labels, vocab):\n",
    "    \"\"\"Converts label IDs to tokens using the provided vocabulary.\"\"\"\n",
    "    tokens = [vocab[label.item()] for label in labels.view(-1)]\n",
    "    return tokens\n",
    "\n",
    "# Example usage\n",
    "# Assuming `reshaped_labels` contains the predicted label IDs of shape [1, 24, 13]\n",
    "tokens = convert_labels_to_tokens(reshaped_labels, vocab)\n",
    "\n",
    "# Optional: Reshape tokens back to the original structure for visualization\n",
    "tokens_reshaped = [\n",
    "    [tokens[i * 13 + j] for j in range(13)] for i in range(24)\n",
    "]\n",
    "\n",
    "# Print tokens\n",
    "pprint(tokens_reshaped)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
